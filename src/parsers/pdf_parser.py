"""
PDF æ–‡æ¡£è§£æžå™¨
è´Ÿè´£å°† PDF æ–‡æ¡£è§£æžä¸º ContentSegment åˆ—è¡¨
"""
import os
import csv
import fitz  # PyMuPDF
from pathlib import Path
from typing import List, Dict, Any, Iterator, Tuple

from ..core.schema import ContentSegment, Settings
from ..core.exceptions import DocumentParseError
from .tools import process_unified_toc
from ..utils.logger import get_logger
from .base import BaseDocPipeline

logger = get_logger(__name__)


class PDFParser(BaseDocPipeline):
    """PDF æ–‡æ¡£è§£æžå™¨"""

    def __init__(self, file_path: Path, cache_path: Path, settings: Settings):
        super().__init__(file_path, cache_path, settings)
        self.doc: fitz.Document = None

    def _load_metadata(self):
        """
        åŠ è½½å…ƒæ•°æ®å¹¶é€‚é… process_unified_toc æž¶æž„ã€‚
        æ”¯æŒï¼šCSV è‡ªå®šä¹‰ -> PDF åŽŸç”Ÿ TOC -> çº¯é¡µç å›žé€€ã€‚
        """
        self.doc = fitz.open(str(self.file_path))

        # 1. å®šä¹‰ä¸­é—´å±‚ï¼šæ ‡å‡†ä¸‰å…ƒç»„åˆ—è¡¨
        # æ¯ä¸€é¡¹ç»“æž„: {'level': int, 'title': str, 'key': int}
        standardized_items = []

        # =========================================================
        # åˆ†æ”¯ A: å°è¯•åŠ è½½ CSV è‡ªå®šä¹‰ç›®å½• (ä¼˜å…ˆçº§æœ€é«˜)
        # =========================================================
        # ä¿®æ­£: ä»Ž settings.document è¯»å–æœ€ç»ˆç”Ÿæ•ˆçš„ TOC è·¯å¾„
        if self.settings.document.custom_toc_path and self.settings.document.custom_toc_path.exists():
            logger.info(f"Loading custom TOC from CSV: {self.settings.document.custom_toc_path}")
            try:
                # utf-8-sig å…¼å®¹ Excel ä¿å­˜çš„ CSV
                with open(self.settings.document.custom_toc_path, 'r', encoding='utf-8-sig') as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        # å¥å£®æ€§è¯»å–ï¼šå¤„ç† CSV åˆ—åå¤§å°å†™æˆ–ç©ºæ ¼
                        # å‡è®¾æ ‡å‡†åˆ—å: Page, Title, Level (å¯é€‰)
                        row_lower = {k.lower().strip(): v for k, v in row.items()}

                        page_str = row_lower.get('page') or row_lower.get('é¡µç ')
                        if not page_str: continue

                        p_idx = int(page_str) - 1 # ç”¨æˆ·ä¹ æƒ¯ 1-based, å†…éƒ¨é€»è¾‘ 0-based

                        title = row_lower.get('title') or row_lower.get('æ ‡é¢˜') or f"Page {p_idx+1}"
                        level_str = row_lower.get('level') or row_lower.get('å±‚çº§') or "1"

                        if p_idx >= 0:
                            standardized_items.append({
                                'level': int(level_str),
                                'title': title.strip(),
                                'key': p_idx
                            })
            except Exception as e:
                logger.error(f"Failed to parse CSV TOC: {e}. Falling back to native TOC.")
                standardized_items = [] # è§£æžå¤±è´¥ï¼Œæ¸…ç©ºä»¥è§¦å‘å›žé€€

        # =========================================================
        # åˆ†æ”¯ B: å°è¯•åŠ è½½ PDF åŽŸç”Ÿ TOC (å¦‚æžœ CSV ä¸ºç©º)
        # =========================================================
        if not standardized_items:
            # fitz.get_toc() è¿”å›ž: [[lvl, title, page, ...], ...]
            raw_toc = self.doc.get_toc()
            if raw_toc:
                logger.info("Loading native PDF TOC.")
                for item in raw_toc:
                    lvl = item[0]
                    title = item[1]
                    page_num = item[2]

                    p_idx = page_num - 1
                    if p_idx >= 0:
                        standardized_items.append({
                            'level': lvl,
                            'title': title,
                            'key': p_idx
                        })

        # =========================================================
        # åˆ†æ”¯ C: çº¯é¡µç å›žé€€æ¨¡å¼ (å¦‚æžœä»¥ä¸Šéƒ½ä¸ºç©º)
        # =========================================================
        is_fallback_mode = False
        if not standardized_items:
            logger.info("No TOC found. Falling back to Page-as-Chapter mode.")
            is_fallback_mode = True
            # æ¯ä¸€é¡µéƒ½ä½œä¸ºä¸€ä¸ª Level 1 çš„ç« èŠ‚
            for i in range(len(self.doc)):
                standardized_items.append({
                    'level': 1,
                    'title': f"Page {i+1}",
                    'key': i
                })

        # =========================================================
        # 2. ç»Ÿä¸€è°ƒç”¨æ ¸å¿ƒç­–ç•¥
        # =========================================================

        # èŽ·å–é¢åŒ…å±‘å¼€å…³ (é»˜è®¤å¼€å¯)
        use_bc = self.settings.processing.use_breadcrumb

        # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æžœæ˜¯çº¯é¡µç å›žé€€æ¨¡å¼ï¼Œå¼ºåˆ¶å…³é—­é¢åŒ…å±‘
        # å¦åˆ™ä¼šå˜æˆ "Page 1 > Page 2 > Page 3..." è¿™ç§è’è°¬çš„å±‚çº§
        if is_fallback_mode:
            use_bc = False

        # è°ƒç”¨ process_unified_toc ç”Ÿæˆæœ€ç»ˆ Map
        # ç»“æžœæ ¼å¼: { 0: {"title": "...", "level": 1}, 5: {"title": "...", "level": 2} }
        self.chapter_map = process_unified_toc(standardized_items, use_breadcrumb=use_bc)

        # (å¯é€‰) ä¿å­˜ raw items ä¾› process_flow è¿›è¡Œé¢„ç¿»è¯‘ä½¿ç”¨
        self.raw_toc_entries = standardized_items

        logger.info(f"Metadata loaded. Chapter Map contains {len(self.chapter_map)} entries.")

    def _iter_content_units(self) -> Iterator[Tuple[int, str, str]]:
        """
        æ ¹æ®æ¨¡å¼ Yield å†…å®¹ã€‚
        Vision æ¨¡å¼ -> type='image', content=path
        Text æ¨¡å¼ -> type='text', content=string
        """
        use_vision = self.settings.processing.use_vision_mode
        # --- Text æ¨¡å¼ ---
        # æ ¹æ® settings.document.page_range è¿›è¡Œé¡µé¢åˆ‡å‰²
        actual_start_page = 0
        actual_end_page = len(self.doc) # æ€»é¡µæ•°

        if self.settings.document.page_range:
            user_start, user_end = self.settings.document.page_range
            
            # å°†ç”¨æˆ·è¾“å…¥çš„ 1-based è½¬æ¢ä¸º 0-based ç´¢å¼•
            potential_start_idx = user_start - 1
            potential_end_idx = user_end # range æ˜¯ exclusive çš„ï¼Œæ‰€ä»¥ç›´æŽ¥ç”¨ user_end
            
            # ç¡®ä¿èŒƒå›´ä¸è¶…å‡ºæ–‡æ¡£å®žé™…é¡µæ•°
            actual_start_page = max(0, potential_start_idx)
            actual_end_page = min(len(self.doc), potential_end_idx)

            logger.info(f"ðŸ“„ é¡µé¢èŒƒå›´åˆ‡å‰²: ç”¨æˆ·è¯·æ±‚ {user_start}-{user_end}ï¼Œå®žé™…å¤„ç† {actual_start_page + 1}-{actual_end_page}")
            if actual_start_page >= actual_end_page:
                logger.warning(f"âš ï¸ è®¾å®šçš„é¡µé¢èŒƒå›´ {user_start}-{user_end} æ— æ•ˆæˆ–è¶…å‡ºæ–‡æ¡£èŒƒå›´ï¼Œå°†è·³è¿‡é¡µé¢è§£æžã€‚")
                return # èŒƒå›´æ— æ•ˆï¼Œä¸ç”Ÿæˆä»»ä½•å†…å®¹

        for i in range(actual_start_page, actual_end_page):
            page = self.doc[i]

            if use_vision:
                # --- Vision æ¨¡å¼ ---
                img_path = self._save_page_image(page, i)
                if img_path:
                    # yield (é¡µç , å›¾ç‰‡è·¯å¾„, ç±»åž‹)
                    yield i, img_path, "image"
            else:
                # --- Text æ¨¡å¼ ---
                text = self._extract_text(page, i)
                # yield (é¡µç , æ–‡æœ¬å†…å®¹, ç±»åž‹)
                yield i, text, "text"

    def _save_page_image(self, page, page_idx) -> str:
        """
        ä»¥ 200 DPI æ¸²æŸ“è£åˆ‡åŽçš„é¡µé¢å›¾ç‰‡ã€‚
        ç›´æŽ¥åœ¨æ¸²æŸ“é˜¶æ®µæ ¹æ® Settings é‡Œçš„ Margin å‚æ•°ç§»é™¤é¡µçœ‰é¡µè„šã€‚
        """
        try:
            # 1. å‡†å¤‡ç›®å½•
            project_dir = self.cache_path.parent

            # åœ¨é¡¹ç›®ç›®å½•ä¸‹åˆ›å»º images æ–‡ä»¶å¤¹
            image_dir = project_dir / "images"
            image_dir.mkdir(parents=True, exist_ok=True)

            # 2. ç”Ÿæˆæ–‡ä»¶å
            filename = f"page_{page_idx + 1:04d}.jpg"
            full_path = image_dir / filename

            if full_path.exists():
                return str(full_path.resolve())

            # 4. è®¡ç®—è£åˆ‡åŒºåŸŸ
            clip_rect = self._get_crop_rect(page)

            # 5. æ¸²æŸ“å›¾ç‰‡
            zoom = 200 / 72  # 200 DPI
            mat = fitz.Matrix(zoom, zoom)
            pix = page.get_pixmap(matrix=mat, clip=clip_rect, alpha=False)

            # 6. ä¿å­˜
            pix.save(str(full_path))
            return str(full_path.resolve())

        except Exception as e:
            logger.error(f"Failed to render image for page {page_idx}: {e}")
            return ""

    def _extract_text(self, page, page_idx) -> str:
        """
        æå–é¡µé¢æ–‡æœ¬ï¼Œæ ¹æ® settings é‡Œçš„ç™¾åˆ†æ¯”å‚æ•°è¿›è¡Œè£åˆ‡ (Clip)ã€‚
        """
        try:
            # è®¡ç®—è£åˆ‡åŒºåŸŸ
            clip_rect = self._get_crop_rect(page)

            # æå–æ–‡æœ¬
            text = page.get_text("text", clip=clip_rect, sort=True)
            return text.strip()

        except Exception as e:
            logger.error(f"Failed to extract text from page {page_idx}: {e}")
            return ""

    def _get_crop_rect(self, page: fitz.Page) -> fitz.Rect:
        """è®¡ç®—è£åˆ‡çŸ©å½¢"""
        w = page.rect.width
        h = page.rect.height

        # èŽ·å–è¾¹è·è®¾ç½®
        m_top = self.settings.document.margin_top or 0.0
        m_bottom = self.settings.document.margin_bottom or 0.0
        m_left = self.settings.document.margin_left or 0.0
        m_right = self.settings.document.margin_right or 0.0

        # è®¡ç®—åæ ‡
        x0 = w * m_left
        y0 = h * m_top
        x1 = w * (1.0 - m_right)
        y1 = h * (1.0 - m_bottom)

        # å®‰å…¨æ£€æŸ¥
        if x0 >= x1 or y0 >= y1:
            return page.rect  # è¿”å›žå…¨é¡µ

        return fitz.Rect(x0, y0, x1, y1)
