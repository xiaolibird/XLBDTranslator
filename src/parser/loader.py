"""
æ–‡æ¡£åŠ è½½å™¨ (DocumentLoader)
ç»Ÿä¸€å…¥å£ï¼Œè´Ÿè´£æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©åˆé€‚çš„è§£æå™¨å¹¶ç®¡ç†ç¼“å­˜
"""

import json
from pathlib import Path

from ..core.exceptions import DocumentFormatError
from ..core.schema import ContentSegment, SegmentList, Settings
from ..utils.logger import get_logger
from .formats import EPUBParser, PDFParser

logger = get_logger(__name__)


class DocumentLoader:
    """æ–‡æ¡£åŠ è½½å™¨ - å·¥å‚æ¨¡å¼å…¥å£"""

    def __init__(self, settings: Settings):
        self.settings = settings

    def load_document(self, file_path: Path, cache_path: Path) -> SegmentList:
        """
        åŠ è½½æ–‡æ¡£çš„ä¸»å…¥å£

        Args:
            file_path: æ–‡æ¡£æ–‡ä»¶è·¯å¾„
            cache_path: ç¼“å­˜æ–‡ä»¶è·¯å¾„

        Returns:
            ContentSegment åˆ—è¡¨
        """
        ext = file_path.suffix.lower()

        # æ£€æŸ¥ç¼“å­˜
        if self.settings.processing.enable_cache and cache_path.exists():
            try:
                with open(cache_path, "r", encoding="utf-8") as f:
                    raw_data = json.load(f)
                    segments = [ContentSegment(**item) for item in raw_data]
                logger.info(f"âœ… Loaded {len(segments)} segments from cache.")
                return segments
            except Exception as e:
                logger.warning(f"âš ï¸ Cache file corrupted: {e}. Will re-parse document.")

        # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©è§£æå™¨
        if ext == ".pdf":
            parser = PDFParser(file_path, cache_path, self.settings)
        elif ext == ".epub":
            parser = EPUBParser(file_path, cache_path, self.settings)
        else:
            raise DocumentFormatError(f"Unsupported file format: {ext}")

        # è§£ææ–‡æ¡£
        segments = parser.run()

        # ä¿å­˜ç¼“å­˜
        self._save_cache(cache_path, segments)

        return segments

    def _save_cache(self, cache_path: Path, segments: SegmentList):
        """ä¿å­˜è§£æç»“æœåˆ°ç¼“å­˜"""
        try:
            cache_path.parent.mkdir(parents=True, exist_ok=True)
            data = [seg.model_dump() for seg in segments]
            with open(cache_path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ’¾ Cache saved: {len(segments)} segments.")
        except Exception as e:
            logger.error(f"âš ï¸ Failed to save cache: {e}")


# ä¾¿æ·å‡½æ•°
def load_document_structure(
    file_path: Path, cache_path: Path, settings: Settings
) -> SegmentList:
    """
    åŠ è½½æ–‡æ¡£ç»“æ„çš„ä¾¿æ·å‡½æ•°

    Args:
        file_path: æ–‡æ¡£è·¯å¾„
        cache_path: ç¼“å­˜è·¯å¾„
        settings: è®¾ç½®

    Returns:
        ContentSegment åˆ—è¡¨
    """
    loader = DocumentLoader(settings)
    return loader.load_document(file_path, cache_path)
