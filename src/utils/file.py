"""
æ–‡ä»¶æ“ä½œå·¥å…·
"""
import os
import re
from pathlib import Path
from typing import Optional
from datetime import datetime
import hashlib

from ..core.schema import Settings


def clean_filename(filename: str) -> str:
    """æ¸…ç†æ–‡ä»¶åï¼Œå»é™¤ç‰¹æ®Šå­—ç¬¦"""
    return re.sub(r'[\\/*?:"<>|]', "", filename).replace(" ", "_")


def get_file_hash(file_path: Path, algorithm: str = 'md5') -> str:
    """
    è®¡ç®—æ–‡ä»¶çš„å“ˆå¸Œå€¼ (MD5 or SHA256).
    """
    hash_func = hashlib.new(algorithm)
    with open(file_path, 'rb') as f:
        #é€å—è¯»å–ä»¥å¤„ç†å¤§æ–‡ä»¶
        for chunk in iter(lambda: f.read(4096), b""):
            hash_func.update(chunk)
    return hash_func.hexdigest()


def create_output_directory(
    project_name: str, 
    output_base_dir: str
) -> Path:
    """
    åŸºäºé¡¹ç›®å”¯ä¸€æ ‡è¯† (å¦‚ MD5-hash) åˆ›å»ºå¹¶è¿”å›é¡¹ç›®ç›®å½•ã€‚
    """
    # ç¡®ä¿åŸºç¡€è¾“å‡ºç›®å½•å­˜åœ¨
    base_dir = Path(output_base_dir)
    base_dir.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºé¡¹ç›®ç›®å½•
    project_dir = base_dir / project_name
    project_dir.mkdir(parents=True, exist_ok=True)
    
    return project_dir


def get_last_checkpoint_id(md_path: Path) -> int:
    """è¯»å– Markdown æ–‡ä»¶ï¼Œæ‰¾åˆ°æœ€åä¸€ä¸ªå·²å®Œæˆçš„ Segment ID"""
    if not md_path.exists():
        return -1

    try:
        content = md_path.read_text(encoding='utf-8')

        # å°è¯•åŒ¹é…æ–°æ ¼å¼
        ids = re.findall(r'ğŸ”– \*\*Segment (\d+)\*\*', content)
        if not ids:
            # å°è¯•åŒ¹é…æ—§æ ¼å¼
            ids = re.findall(r'### Segment (\d+)', content)

        return int(ids[-1]) if ids else -1

    except Exception:
        return -1


def recover_context_from_file(md_path: Path, max_chars: int = 2000) -> str:
    """ä»æ–‡ä»¶æœ«å°¾æ¢å¤ä¸Šä¸‹æ–‡"""
    if not md_path.exists():
        return ""

    try:
        with open(md_path, 'rb') as f:
            f.seek(0, os.SEEK_END)
            file_size = f.tell()

            if file_size == 0:
                return ""

            read_size = min(file_size, max_chars + 512)
            f.seek(-read_size, os.SEEK_END)

            tail_bytes = f.read(read_size)
            tail_text = tail_bytes.decode('utf-8', errors='ignore')

        return tail_text[-max_chars:]

    except Exception:
        return ""


def save_segments_cache(cache_path: Path, segments: list) -> None:
    """ä¿å­˜ç‰‡æ®µç¼“å­˜"""
    import json

    try:
        cache_path.parent.mkdir(parents=True, exist_ok=True)
        data = [seg.model_dump() for seg in segments]
        with open(cache_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"Failed to save cache: {e}")


def load_segments_cache(cache_path: Path) -> Optional[list]:
    """åŠ è½½ç‰‡æ®µç¼“å­˜"""
    import json
    from ..core.schema import ContentSegment

    if not cache_path.exists():
        return None

    try:
        with open(cache_path, 'r', encoding='utf-8') as f:
            raw_data = json.load(f)
            return [ContentSegment(**item) for item in raw_data]
    except Exception:
        return None
