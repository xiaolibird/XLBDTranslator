import os
import re
import datetime
from bs4 import BeautifulSoup


from pathlib import Path

def clean_filename(filename):
    """æ¸…ç†æ–‡ä»¶åï¼Œå»é™¤ç‰¹æ®Šå­—ç¬¦"""
    return re.sub(r'[\\/*?:"<>|]', "", filename).replace(" ", "_")

def create_output_directory(input_file_path: str, mode_name: str, base_dir: Path) -> Path:
    """åˆ›å»ºå¹¶è¿”å›ä¸€ä¸ªåŸºäºæ—¥æœŸã€æ–‡ä»¶åå’Œæ¨¡å¼çš„é¡¹ç›®ä¸“å±è¾“å‡ºç›®å½•ã€‚"""
    date_str = datetime.datetime.now().strftime("%Y%m%d")
    base_name = Path(input_file_path).stem
    safe_name = clean_filename(base_name)
    safe_mode = clean_filename(mode_name)
    
    folder_name = f"{date_str}_{safe_name}_{safe_mode}"
    project_path = base_dir / folder_name
    
    # exist_ok=True ç¡®ä¿å¦‚æœç›®å½•å·²å­˜åœ¨ï¼Œä»£ç ä¸ä¼šæŠ¥é”™
    project_path.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ“‚ é¡¹ç›®å·¥ä½œç›®å½•ä½äº: {project_path}")
        
    return project_path

def get_last_checkpoint_id(md_path):
    """
    è¯»å– Markdown æ–‡ä»¶ï¼Œæ‰¾åˆ°æœ€åä¸€ä¸ªå·²å®Œæˆçš„ Segment IDã€‚
    æ”¯æŒæ–°æ—§ä¸¤ç§æ ¼å¼çš„å…¼å®¹ã€‚
    """
    if not os.path.exists(md_path):
        return -1
        
    try:
        with open(md_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # 1. å°è¯•åŒ¹é…æ–°æ ¼å¼: ğŸ”– **Segment 101**
        ids = re.findall(r'ğŸ”– \*\*Segment (\d+)\*\*', content)
        
        # 2. å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•åŒ¹é…æ—§æ ¼å¼ (å…¼å®¹æ—§æ–‡ä»¶): ### Segment 101
        if not ids:
            ids = re.findall(r'### Segment (\d+)', content)
        
        if ids:
            return int(ids[-1]) # è¿”å›æœ€åä¸€ä¸ªæ‰¾åˆ°çš„ ID
        return -1
        
    except Exception as e:
        print(f"âš ï¸ è¯»å–è¿›åº¦æ–‡ä»¶å¤±è´¥: {e}")
        return -1

def recover_context_from_file(md_path):
    """ä»æ–‡ä»¶æ¢å¤ä¸Šä¸‹æ–‡"""
    if not os.path.exists(md_path): return ""
    try:
        with open(md_path, 'r', encoding='utf-8') as f:
            f.seek(0, 2)
            file_size = f.tell()
            read_size = min(1000, file_size)
            if read_size == 0: return ""
            f.seek(file_size - read_size)
            return f.read()
    except: return ""

def extract_text_from_epub_item(item):
    """ä» EPUB Item æå–æ–‡æœ¬"""
    try:
        soup = BeautifulSoup(item.get_content(), 'html.parser')
        for script in soup(["script", "style"]):
            script.extract()
        text = soup.get_text()
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        return '\n'.join(chunk for chunk in chunks if chunk)
    except Exception as e:
        print(f"   âš ï¸ Error extracting text from EPUB item: {e}")
        return ""

def render_segment_to_markdown(original_seg: dict, trans_text: str, retain_original: bool) -> str:
    seg_id = original_seg['id']
    original_text = (original_seg.get('text', '') or "").replace('\r', '').strip()
    
    if original_text.startswith("<<IMAGE_PATH"):
        # æå–è·¯å¾„ï¼šå»æ‰å‰ç¼€æ ‡è®°ï¼Œå»æ‰å¯èƒ½çš„åç¼€ '>>'
        # å‡è®¾æ ¼å¼ä¸º <<IMAGE_PATH::/path/to/image.png>> æˆ– <<IMAGE_PATH /path...
        raw_path = original_text.replace("<<IMAGE_PATH", "").replace("::", "").replace(">>", "").strip()
        name, ext = os.path.splitext(raw_path)
        image_path = f"{name}_cropped{ext}"
        
        # æ„å»º Markdown å›¾ç‰‡è¯­æ³•
        # æ ¼å¼: ![Segment ID](æ–‡ä»¶è·¯å¾„)
        md_block = [f"![Image Segment {seg_id}]({image_path})"]
        
        # å¦‚æœå›¾ç‰‡æœ‰å¯¹åº”çš„ç¿»è¯‘æ–‡æœ¬ï¼ˆå¦‚å›¾æ³¨æˆ–OCRç¿»è¯‘ï¼‰ï¼Œå±•ç¤ºåœ¨å›¾ç‰‡ä¸‹æ–¹
        if trans_text:
            # æ¸…ç†ä¸€ä¸‹ç¿»è¯‘æ–‡æœ¬
            clean_trans = trans_text.replace('\\n', '\n').replace('\\"', '"').strip()
            md_block.append(f"\n> ğŸ’¡ **å›¾æ³¨/å†…å®¹è¯‘æ–‡**ï¼š{clean_trans}")
        
        md_block.append(f"\n\nğŸ”– **Segment {seg_id}** (Image)\n---")
        return "\n".join(md_block)

    # 1. åŸºç¡€æ¸…ç†ï¼šå¤„ç†è½¬ä¹‰ç¬¦å’Œå¼•å·
    trans_text = trans_text.replace('\\n', '\n').replace('\\"', '"').strip()

    # 2. æ ‡è®°å¤„ç†é€»è¾‘ (Regex)
    # ç« èŠ‚ï¼š## [Chapter X] -> ## ğŸ“– Chapter X
    def sub_chapter(m): return f"{m.group(1)}ğŸ“– {m.group(2)}"
    # é¡µç ï¼š###### [Page: 10] -> ###### --- åŸæ–‡ç¬¬ 11 é¡µ ---
    def sub_page(m): return f"\n\n###### --- åŸæ–‡ç¬¬ {int(m.group(1)) + 1} é¡µ --- \n\n"

    # 3. å¤„ç†è¯‘æ–‡ (ä¿ç•™å¹¶ç¾åŒ–æ ‡è®°)
    trans_text = re.sub(r'(^##\s*)(\[.*?\])', sub_chapter, trans_text, flags=re.MULTILINE)
    trans_text = re.sub(r'######\s*\[Page:\s*(\d+)\]', sub_page, trans_text)

    # 4. å¤„ç†åŸæ–‡ (å…³é”®ï¼šå½»åº•ç§»é™¤æ ‡è®°ï¼Œé˜²æ­¢åŒè¯­å¯¹ç…§æ—¶é‡å¤è¾“å‡º)
    if retain_original:
        # åœ¨åŸæ–‡ä¸­ï¼Œå°†è¿™äº›ç»“æ„æ€§æ ‡è®°æ›¿æ¢ä¸ºç©ºï¼Œåªä¿ç•™çº¯æ–‡æœ¬å†…å®¹
        original_text = re.sub(r'(^##\s*)(\[.*?\])', '', original_text, flags=re.MULTILINE)
        original_text = re.sub(r'######\s*\[Page:\s*\d+\]', '', original_text)

    # 5. ç”Ÿæˆé¢„è§ˆä¸å…ƒæ•°æ®
    # é¢„è§ˆå»é™¤ Markdown ç¬¦å·ï¼Œä»…å–å‰70å­—
    preview = re.sub(r'[#*-]', '', original_text).replace('\n', ' ').strip()[:70]
    header_block = f"\n\nğŸ”– **Segment {seg_id}**\n"
    if not retain_original:
        header_block += f'_Original: "{preview}..."_\n\n'

    # 6. å†…å®¹æ’ç‰ˆ (æ ¸å¿ƒæ¸²æŸ“)
    output_blocks = [header_block]
    
    # è¾…åŠ© lambdaï¼šæ¸…ç†è¡Œå¹¶å»é™¤å°¾éƒ¨åæ–œæ 
    clean_split = lambda t: [l.rstrip('\\').strip() for l in t.split('\n')]

    if retain_original:
        # --- åŒè¯­æ¨¡å¼ ---
        # æŒ‰ç…§åŒæ¢è¡Œåˆ†æ®µï¼Œå¯¹é½æ®µè½
        orig_paras = [p for p in original_text.split('\n\n') if p.strip()]
        trans_paras = [p for p in trans_text.split('\n\n') if p.strip()]
        
        for i in range(max(len(orig_paras), len(trans_paras))):
            block = []
            p_orig = clean_split(orig_paras[i]) if i < len(orig_paras) else []
            p_trans = clean_split(trans_paras[i]) if i < len(trans_paras) else []

            # æ¸²æŸ“åŸæ–‡ (å·²ç§»é™¤ Tagï¼Œå…¨æ˜¯çº¯æ–‡æœ¬)
            if p_orig:
                block.append(f"åŸæ–‡ï¼š{p_orig[0]}")
                block.extend([f"      {line}" for line in p_orig[1:]])
            
            # æ¸²æŸ“è¯‘æ–‡ (åŒ…å«ç¾åŒ–åçš„ Tag)
            if p_trans:
                for j, line in enumerate(p_trans):
                    # å¦‚æœæ˜¯æ ‡é¢˜æˆ–åˆ†éš”ç¬¦ï¼Œé¡¶æ ¼å†™ï¼Œä¿æŒ Markdown æ ¼å¼
                    if line.startswith('#'):
                        block.append(f"\n{line}\n")
                    # æ™®é€šæ–‡æœ¬æ·»åŠ å¼•ç”¨å‰ç¼€
                    elif j == 0:
                        block.append(f"> è¯‘æ–‡ï¼š{line}")
                    else:
                        block.append(f">       {line}")
            
            if block: output_blocks.append("\n".join(block))

    else:
        # --- çº¯è¯‘æ–‡æ¨¡å¼ ---
        lines = clean_split(trans_text)
        formatted = []
        for line in lines:
            # æ ‡é¢˜/åˆ†éš”ç¬¦ç‹¬ç«‹æˆè¡Œï¼Œæ­£æ–‡æ”¾å…¥å¼•ç”¨å—
            if line.startswith('#'):
                formatted.append(f"\n{line}\n")
            else:
                formatted.append(f"> {line}" if line else ">")
        output_blocks.append("\n".join(formatted))

    return "\n\n".join(output_blocks) + "\n\n---"

def recover_context_from_file(md_path, max_chars: int = 2000) -> str:
    """
    ä»æ–‡ä»¶æœ«å°¾å®‰å…¨åœ°æ¢å¤ä¸Šä¸‹æ–‡ï¼Œé¿å…å› å¤šå­—èŠ‚å­—ç¬¦æˆªæ–­å¯¼è‡´é”™è¯¯ã€‚
    å®ƒä¼šè¯»å–æ¯”éœ€æ±‚ç¨å¤šçš„æ•°æ®ï¼Œç„¶åæŒ‰è¡Œåˆ†å‰²ï¼Œç¡®ä¿åªè¿”å›å®Œæ•´çš„è¡Œã€‚
    """
    if not os.path.exists(md_path):
        return ""
    
    try:
        with open(md_path, 'rb') as f: # ä»¥äºŒè¿›åˆ¶æ¨¡å¼æ‰“å¼€ä»¥ç²¾ç¡®å®šä½
            f.seek(0, os.SEEK_END)
            file_size = f.tell()
            
            if file_size == 0:
                return ""
            
            read_size = min(file_size, max_chars + 512) # å¤šè¯»ä¸€ç‚¹ä»¥ä¿è¯èƒ½æ‰¾åˆ°æ¢è¡Œç¬¦
            f.seek(-read_size, os.SEEK_END)
            
            # è¯»å–äºŒè¿›åˆ¶æ•°æ®å¹¶è§£ç 
            tail_bytes = f.read(read_size)
            tail_text = tail_bytes.decode('utf-8', errors='ignore')

        # ä»åå‘å‰æˆªå–æ‰€éœ€é•¿åº¦çš„å®Œæ•´æ–‡æœ¬
        # è¿™æ¯”å¤æ‚çš„é€è¡Œè¯»å–æ›´é«˜æ•ˆä¸”åŒæ ·å®‰å…¨
        return tail_text[-max_chars:]

    except Exception as e:
        print(f"âš ï¸ æ¢å¤ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
        return ""

def is_likely_chinese(text):
    """ç®€å•æ£€æµ‹æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦"""
    for char in text:
        if '\u4e00' <= char <= '\u9fff':
            return True
    return False