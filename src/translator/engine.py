"""
Gemini ç¿»è¯‘å®¢æˆ·ç«¯
ä½¿ç”¨ tenacity è¿›è¡Œé‡è¯•ç®¡ç†
"""
import asyncio
import base64
import json
import time
import re
import mimetypes
from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor
from urllib import request, error

from google import genai
from google.genai import types
from google.genai import errors as genai_errors
from google.api_core.exceptions import GoogleAPICallError, ResourceExhausted, ServiceUnavailable, ClientError, DeadlineExceeded
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

from ..core.schema import Settings, ContentSegment, TranslationMap, SegmentList
from ..core.exceptions import (
    APIError, APIRateLimitError, APITimeoutError, APIAuthenticationError,
    JSONParseError, TranslationError
)
from .base import BaseTranslator, BaseAsyncTranslator
from .support import CachePersistenceManager, PromptManager
from ..utils.logger import get_logger

logger = get_logger(__name__)


class GeminiTranslator(BaseTranslator):
    """Gemini ç¿»è¯‘å®¢æˆ·ç«¯ã€‚
    
    ç»§æ‰¿è‡ª BaseTranslatorï¼Œå®ç° Google Gemini çš„å…·ä½“ç¿»è¯‘é€»è¾‘ã€‚
    """

    def __init__(
        self, 
        settings: Settings, 
        cache_manager: Optional[CachePersistenceManager] = None
    ):
        """
        Args:
            settings: å…¨å±€è®¾ç½®å¯¹è±¡ï¼ˆåŒ…å«document_pathç”¨äºè®¡ç®—hashï¼‰
            cache_manager: ç¼“å­˜æŒä¹…åŒ–ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨ï¼Œå¦åˆ™è‡ªåŠ¨åˆ›å»º
        """
        # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        super().__init__(settings)
        
        self.generation_config = {}
        self.cache_refs: Dict[str, str] = {}
        self._async_translator = None  # æ‡’åŠ è½½å¼‚æ­¥ç¿»è¯‘å™¨
        self._client: Optional[genai.Client] = None
        self._base_generation_config: Optional[types.GenerateContentConfig] = None
        
        # åˆå§‹åŒ– Prompt ç®¡ç†å™¨
        self.prompt_manager = PromptManager(settings)
        
        # åˆå§‹åŒ–ç¼“å­˜æŒä¹…åŒ–ç®¡ç†å™¨ï¼ˆä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„ï¼Œå¦åˆ™æ ¹æ®doc_hashåˆ›å»ºï¼‰
        self.cache_persistence = cache_manager
        if self.cache_persistence is None and settings.processing.enable_gemini_caching and self.doc_hash:
            self.cache_persistence = CachePersistenceManager(settings)

        # é…ç½® API
        self._configure_api()

        # åˆå§‹åŒ–æ¨¡å‹ï¼ˆæ–° SDKï¼šClient + GenerateContentConfigï¼›é€šè¿‡é€‚é…å™¨ä¿ç•™æ—§è°ƒç”¨å½¢æ€ï¼‰
        self.model = self._create_model()
        
        # åˆ›å»ºSystem Instructionç¼“å­˜ï¼ˆå§”æ‰˜ç»™ç¼“å­˜ç®¡ç†å™¨ï¼‰
        if settings.processing.enable_gemini_caching and self.cache_persistence:
            # ä½¿ç”¨translation_mode_entityçš„nameä½œä¸ºdisplay_nameï¼ˆå¯é€‰ï¼‰
            mode_name = getattr(settings.processing.translation_mode_entity, 'name', None)
            cache_name = self.cache_persistence.get_or_create_system_cache(
                system_instruction=self.prompt_manager.get_system_instruction(use_vision=settings.processing.use_vision_mode),
                model_name=settings.api.gemini_model,
                display_name=f"sys_{mode_name}" if mode_name else None
            )
            if cache_name:
                self.cache_refs['system'] = cache_name
                logger.info(f"âœ… System Instruction ç¼“å­˜å·²å°±ç»ª: {cache_name[:50]}...")
    
    @property
    def async_translator(self):
        """æ‡’åŠ è½½å¼‚æ­¥ç¿»è¯‘å™¨"""
        if self._async_translator is None:
            self._async_translator = AsyncGeminiTranslator(self)
        return self._async_translator
    

    def _configure_api(self):
        """é…ç½® Gemini API"""
        try:
            # Gemini Developer API
            self._client = genai.Client(api_key=self.settings.api.gemini_api_key)
        except Exception as e:
            raise APIAuthenticationError(
                "Failed to configure Gemini API. Check your API key.",
                context={"error": str(e)}
            )

    def _create_model(self):
        """åˆ›å»º Gemini æ¨¡å‹å®ä¾‹ï¼ˆæ–° SDKï¼šä»…å‡†å¤‡ base configï¼Œå¹¶è¿”å›é€‚é…å™¨ï¼‰"""

        if self._client is None:
            raise APIAuthenticationError("Gemini client is not configured")

        safety_settings = [
            types.SafetySetting(category="HARM_CATEGORY_HARASSMENT", threshold="BLOCK_NONE"),
            types.SafetySetting(category="HARM_CATEGORY_HATE_SPEECH", threshold="BLOCK_NONE"),
            types.SafetySetting(category="HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold="BLOCK_NONE"),
            types.SafetySetting(category="HARM_CATEGORY_DANGEROUS_CONTENT", threshold="BLOCK_NONE"),
        ]

        self.generation_config = {
            "temperature": 0.2,  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„è¾“å‡º
            "top_p": 0.95,
            "response_mime_type": "application/json",
            "max_output_tokens": 8192,
        }

        # æ ¹æ®processingæ¨¡å¼é€‰æ‹©å¯¹åº”çš„system instructionï¼ˆåŒ…å«promptå›ºå®šéƒ¨åˆ†ï¼‰
        use_vision = self.settings.processing.use_vision_mode
        system_instruction = self.prompt_manager.get_system_instruction(use_vision=use_vision)

        self._base_generation_config = types.GenerateContentConfig(
            system_instruction=system_instruction,
            safety_settings=safety_settings,
            **self.generation_config,
        )

    def _generate_content(self, contents: Any, generation_config: Optional[Dict[str, Any]] = None, use_cache: bool = True, purpose: str = "API Call") -> Any:
        """ç»Ÿä¸€çš„å†…å®¹ç”Ÿæˆæ–¹æ³•ï¼Œå¤„ç†ç¼“å­˜é€»è¾‘
        
        Args:
            contents: è¦å‘é€çš„å†…å®¹
            generation_config: ç”Ÿæˆé…ç½®è¦†ç›–ï¼ˆå­—å…¸æ ¼å¼ï¼‰
            use_cache: æ˜¯å¦å°è¯•ä½¿ç”¨ç³»ç»Ÿç¼“å­˜
            purpose: è°ƒç”¨ç›®çš„ï¼ˆç”¨äºæ—¥å¿—ï¼‰
            
        Returns:
            APIå“åº”å¯¹è±¡
        """
        # æ„å»ºé…ç½®
        config_update = generation_config or {}
        config = self._base_generation_config.model_copy(update=config_update)
        
        # å¤„ç†ç¼“å­˜
        cache_name = self.cache_refs.get("system") if use_cache else None
        if cache_name:
            config = config.model_copy(update={
                "cached_content": cache_name,
                "system_instruction": None,
                "tools": None,
                "tool_config": None,
            })
        
        try:
            response = self._client.models.generate_content(
                model=self.settings.api.gemini_model,
                contents=contents,
                config=config,
            )
            if cache_name:
                logger.debug(f"ğŸ”„ {purpose} ä½¿ç”¨ Gemini Cache: {cache_name[:30]}...")
            return response
        except Exception as e:
            # ç¼“å­˜å¤±è´¥æ—¶é™çº§
            if cache_name:
                logger.warning(f"âš ï¸  {purpose} ç¼“å­˜ä½¿ç”¨å¤±è´¥ï¼Œé™çº§ä¸ºæ™®é€šè°ƒç”¨: {e}")
                config_no_cache = config.model_copy(update={
                    "cached_content": None,
                    "system_instruction": self._base_generation_config.system_instruction,
                })
                return self._client.models.generate_content(
                    model=self.settings.api.gemini_model,
                    contents=contents,
                    config=config_no_cache,
                )
            raise
    


    def _attempt_json_self_correction(
        self,
        original_prompt: str,
        failed_json: str,
        error_message: str,
        retries_left: int,
        is_vision: bool = False,
        image_part: Optional[Any] = None
    ) -> Optional[Any]:
        """
        å°è¯•å¼•å¯¼æ¨¡å‹è‡ªæˆ‘ä¿®æ­£ JSON è¾“å‡ºã€‚
        """
        if retries_left <= 0:
            logger.warning("âŒ JSON è‡ªæˆ‘ä¿®æ­£é‡è¯•æ¬¡æ•°å·²ç”¨å°½ã€‚")
            return None

        logger.info(f"ğŸ”„ å°è¯• JSON è‡ªæˆ‘ä¿®æ­£ (å‰©ä½™ {retries_left} æ¬¡)...")
        repair_prompt_content = self.prompt_manager.format_json_repair_prompt(
            original_prompt=original_prompt,
            broken_json=failed_json,
            error_details=error_message
        )

        try:
            # ä½¿ç”¨ä¸åŸå§‹è¯·æ±‚ç›¸åŒçš„é…ç½®
            gen_cfg = {
                "temperature": self.generation_config["temperature"],
                "top_p": self.generation_config["top_p"],
                "max_output_tokens": self.generation_config["max_output_tokens"],
                "response_mime_type": "application/json",
            }

            content_parts = [repair_prompt_content]
            if is_vision and image_part is not None:
                content_parts.append(image_part)

            response = self.model.generate_content(
                content_parts,
                generation_config=gen_cfg
            )
            # raw_text = response.text.strip()
            raw_text = response.candidates[0].content.parts[0].text
            # å°è¯•è§£æä¿®æ­£åçš„ JSON
            parsed_data = json.loads(raw_text)
            logger.info("âœ… JSON è‡ªæˆ‘ä¿®æ­£æˆåŠŸã€‚")
            return parsed_data
        except (json.JSONDecodeError, GoogleAPICallError, genai_errors.APIError, Exception) as e:
            logger.warning(f"âš ï¸ JSON è‡ªæˆ‘ä¿®æ­£å¤±è´¥ (ç¬¬ {self.settings.processing.json_repair_retries - retries_left + 1} æ¬¡): {e}")
            # é€’å½’é‡è¯•
            return self._attempt_json_self_correction(
                original_prompt=original_prompt,
                failed_json=raw_text if 'raw_text' in locals() else failed_json, # ä¼ å…¥æœ€æ–°çš„å¤±è´¥JSON
                error_message=str(e),
                retries_left=retries_left - 1,
                is_vision=is_vision,
                image_part=image_part
            )

    def translate_batch(
        self,
        segments: SegmentList,
        context: str = "",
        glossary: Optional[Dict[str, str]] = None
    ) -> List[str]:
        """
        æ ¸å¿ƒç¿»è¯‘æ–¹æ³•
        æ ¹æ®å†…å®¹ç±»å‹è‡ªåŠ¨åˆ†æµåˆ°å¯¹åº”å¤„ç†é€»è¾‘
        """
        if not segments:
            return []

        # æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾ç‰‡
        has_image = any(seg.content_type == "image" for seg in segments)

        if has_image:
            return self._translate_vision_batch(segments, context, glossary)
        else:
            return self._translate_text_batch(segments, context, glossary)

    def translate_titles(self, titles: List[str]) -> TranslationMap:
        """ç¿»è¯‘æ ‡é¢˜åˆ—è¡¨"""
        if not titles:
            return {}

        input_json_str = json.dumps(titles, ensure_ascii=False)
        original_prompt = self.prompt_manager.format_title_prompt(input_json_str)

        try:
            response = self._generate_content(
                contents=original_prompt,
                generation_config=self.generation_config,
                use_cache=True,
                purpose="Title Translation"
            )
            raw_text = response.candidates[0].content.parts[0].text
            # è§£æå“åº”ï¼Œå¹¶å¤„ç†è‡ªæˆ‘ä¿®æ­£
            parsed_data = self._handle_json_response_with_correction(
                raw_text,
                original_prompt,
                is_title_translation=True
            )

            # å½’ä¸€åŒ–å¤„ç†
            if isinstance(parsed_data, dict):
                return {str(k): str(v) for k, v in parsed_data.items() if isinstance(v, str)}
            elif isinstance(parsed_data, list) and parsed_data:
                result = {}
                for item in parsed_data:
                    if isinstance(item, dict):
                        for k, v in item.items():
                            if k != 'id':  # è·³è¿‡ id å­—æ®µ
                                result[str(k)] = str(v)
                return result

            return {}

        except Exception as e:
            logger.error(f"Title translation failed even after correction attempts: {e}")
            return {}

    def extract_glossary(self, segments: SegmentList) -> Dict[str, str]:
        """ä»å·²ç¿»è¯‘çš„ç‰‡æ®µä¸­è‡ªåŠ¨æå–æœ¯è¯­è¡¨"""
        logger.info("ğŸ§  æ­£åœ¨æå–æœ¯è¯­è¡¨ä»¥å¢å¼ºåç»­ç¿»è¯‘...")
        if not segments:
            logger.warning("   - æ— å†…å®¹å¯ä¾›æå–æœ¯è¯­è¡¨ã€‚")
            return {}

        # å‡†å¤‡ç”¨äºåˆ†æçš„æ–‡æœ¬
        text_to_analyze = []
        for seg in segments:
            if seg.is_translated:
                text_to_analyze.append(f"Original: {seg.original_text}\nTranslated: {seg.translated_text}\n---")
        
        if not text_to_analyze:
            logger.warning("   - æä¾›çš„ç‰‡æ®µå‡æœªç¿»è¯‘ï¼Œæ— æ³•æå–æœ¯è¯­ã€‚")
            return {}

        content_sample = "\n".join(text_to_analyze)
        
        # æ„å»º Prompt
        original_prompt = f"""
        You are an expert linguist and terminologist.
        Analyze the following pairs of original and translated text. Identify all key, recurring, or specialized terms (like names, places, philosophical concepts, technical jargon) and create a definitive glossary.

        RULES:
        1. The output MUST be a flat JSON object.
        2. Keys are the original English terms.
        3. Values are their corresponding Chinese translations found in the text.
        4. Focus on nouns and proper nouns.
        5. Be precise. The goal is to enforce consistency.

        Example Output Format:
        {{
            "Slavoj Å½iÅ¾ek": "æ–¯æ‹‰æ²ƒçƒ­Â·é½æ³½å…‹",
            "the Real": "å®åœ¨ç•Œ",
            "Objet petit a": "å®¢ä½“å° a"
        }}

        Text to Analyze:
        <text>
        {content_sample[:8000]}
        </text>

        Return ONLY the JSON object.
        """

        try:
            if self._client is None:
                raise APIAuthenticationError("Gemini client is not configured")

            extraction_config = types.GenerateContentConfig(
                response_mime_type="application/json",
                temperature=0.2,
                max_output_tokens=8192,
            )

            response = self._client.models.generate_content(
                model=self.settings.api.gemini_model,
                contents=original_prompt,
                config=extraction_config,
            )
            # raw_text = response.text.strip()
            raw_text = response.candidates[0].content.parts[0].text
            # å¤„ç†è‡ªæˆ‘ä¿®æ­£
            parsed_glossary = self._handle_json_response_with_correction(
                raw_text, 
                original_prompt, 
                is_glossary_extraction=True
            )
            
            # å½’ä¸€åŒ–ä¸åŒå¯èƒ½çš„æ¨¡å‹è¾“å‡ºæ ¼å¼ä¸ºå¹³å¦çš„ {str: str} å½¢å¼
            final_glossary: Dict[str, str] = {}

            if isinstance(parsed_glossary, dict):
                for k, v in parsed_glossary.items():
                    try:
                        if k and v:
                            final_glossary[str(k).strip()] = str(v).strip()
                    except TypeError:
                        # è·³è¿‡ä¸å¯å“ˆå¸Œæˆ–éæ ‡é‡çš„é”®
                        continue

            elif isinstance(parsed_glossary, list):
                for item in parsed_glossary:
                    if isinstance(item, dict):
                        for k, v in item.items():
                            if k and v:
                                final_glossary[str(k).strip()] = str(v).strip()
                    elif isinstance(item, (list, tuple)) and len(item) == 2:
                        k, v = item
                        if k and v:
                            final_glossary[str(k).strip()] = str(v).strip()

            # æ—¥å¿—å’Œè¿”å›
            if final_glossary:
                logger.info(f"   - âœ… æˆåŠŸæå– {len(final_glossary)} ä¸ªæœ¯è¯­ã€‚")
                for k, v in list(final_glossary.items())[:5]:
                    logger.info(f"     - '{k}' -> '{v}'")
                if len(final_glossary) > 5:
                    logger.info("     - ... (æ›´å¤šæœ¯è¯­)")
                return final_glossary

            logger.warning(f"   - âš ï¸ æœ¯è¯­æå–æœªèƒ½äº§ç”Ÿæœ‰æ•ˆå­—å…¸ã€‚åŸå§‹å“åº”ç±»å‹: {type(parsed_glossary)}. åŸå§‹å“åº”ç‰‡æ®µ: {raw_text[:200]}")
            return {}
        except Exception as e:
            logger.error(f"   - âŒ æå–æœ¯è¯­è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return {}

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=1, max=30),
        retry=retry_if_exception_type((APIError, GoogleAPICallError)),
        reraise=True
    )
    def _translate_text_batch(
        self,
        segments: SegmentList,
        context: str,
        glossary: Optional[Dict[str, str]] = None
    ) -> List[str]:
        """æ–‡æœ¬æ‰¹é‡ç¿»è¯‘ï¼ˆå¸¦é‡è¯•ï¼‰"""
        # æ„å»ºè¾“å…¥æ•°æ®
        input_data = [
            {"id": seg.segment_id, "text": seg.original_text}
            for seg in segments
        ]
        input_json = json.dumps(input_data, ensure_ascii=False)

        # æˆªå–ä¸Šä¸‹æ–‡
        safe_context = context[-self.settings.processing.max_context_length:] if context else "No Context"

        # æ ¼å¼åŒ–æœ¯è¯­è¡¨
        if glossary:
            glossary_text = "\n".join([f"- **{k}**: Must be translated as **{v}**" for k, v in glossary.items()])
        else:
            glossary_text = "N/A"

        # æ ¼å¼åŒ–æç¤ºï¼ˆå›ºå®šéƒ¨åˆ†å·²åœ¨system instructionï¼Œä»…å¡«å……åŠ¨æ€å˜é‡ï¼‰
        original_prompt = self.prompt_manager.format_text_prompt(
            context=safe_context,
            input_json=input_json,
            glossary=glossary_text
        )

        response = self._generate_content(
            contents=original_prompt,
            generation_config=self.generation_config,
            use_cache=True,
            purpose="Text Translation"
        )
        
        raw_text = response.candidates[0].content.parts[0].text
        # è§£æå“åº”ï¼Œå¹¶å¤„ç†è‡ªæˆ‘ä¿®æ­£
        output_list = self._handle_json_response_with_correction(
            raw_text, 
            original_prompt, 
            is_text_translation=True
        )

        # æ˜ å°„ç»“æœ
        input_ids = [s.segment_id for s in segments]
        output_map = {
            int(item['id']): str(item.get('translation', ''))
            for item in output_list
            if 'id' in item and str(item['id']).isdigit()
        }

        # ç”Ÿæˆæœ€ç»ˆç»“æœ
        results = []
        for uid in input_ids:
            results.append(output_map.get(uid, "[Failed: Missing translation]"))

        return results

    def _translate_vision_batch(
        self,
        segments: SegmentList,
        context: str,
        glossary: Optional[Dict[str, str]] = None
    ) -> List[str]:
        """è§†è§‰æ‰¹é‡ç¿»è¯‘ï¼ˆä¸²è¡Œå¤„ç†ï¼‰"""
        results = []
        current_context = context[-self.settings.processing.max_context_length:] if context else ""

        for seg in segments:
            try:
                if seg.content_type == "image" and seg.image_path:
                    translation = self._call_vision_api(
                        seg.image_path,
                        current_context
                    )
                    time.sleep(self.settings.processing.vision_rate_limit_delay)
                else:
                    # é™çº§å¤„ç†æ–‡æœ¬
                    fallback_result = self._translate_text_batch([seg], current_context, glossary)
                    translation = fallback_result[0] if fallback_result else "[Fallback Failed]"

                results.append(translation)

                # æ›´æ–°ä¸Šä¸‹æ–‡
                current_context += f"\n{translation}"
                if len(current_context) > self.settings.processing.max_context_length:
                    current_context = current_context[-self.settings.processing.max_context_length:]

            except Exception as e:
                logger.error(f"âŒ Visionç¿»è¯‘å¤±è´¥ (segment {seg.segment_id}): {e}")
                results.append(f"[Failed: {str(e)}]")
                continue

        return results

    def _call_vision_api(self, img_path: str, context: str) -> str:
        """è°ƒç”¨è§†è§‰ APIï¼ˆæ”¯æŒ Gemini Cachingï¼‰"""
        try:
            # ä½¿ç”¨ prompt_manager æ ¼å¼åŒ–æç¤º
            original_prompt = self.prompt_manager.format_vision_prompt(context)

            mime_type, _ = mimetypes.guess_type(img_path)
            mime_type = mime_type or "image/png"
            with open(img_path, "rb") as f:
                image_bytes = f.read()

            image_part = types.Part.from_bytes(data=image_bytes, mime_type=mime_type)

            vision_config = {
                "temperature": self.generation_config["temperature"],
                "top_p": self.generation_config["top_p"],
                "max_output_tokens": self.generation_config["max_output_tokens"],
                "response_mime_type": "application/json",
            }

            response = self._generate_content(
                contents=[original_prompt, image_part],
                generation_config=vision_config,
                use_cache=True,
                purpose="Vision Translation"
            )

            raw_text = (response.text or "").strip()

            # è§£æ JSON å¹¶æå– "translation" å­—æ®µï¼Œå¤„ç†è‡ªæˆ‘ä¿®æ­£
            parsed_json = self._handle_json_response_with_correction(
                raw_text,
                original_prompt,
                is_vision_translation=True,
                image_part=image_part,
            )

            if isinstance(parsed_json, dict) and "translation" in parsed_json:
                return parsed_json["translation"]

            logger.error(
                "âŒ Vision API did not return valid JSON with a 'translation' key even after correction. "
                f"Got: {raw_text[:200]}"
            )
            return "[Failed: Invalid JSON Response]"

        except Exception as e:
            logger.error(f"âŒ Vision APIè°ƒç”¨å¤±è´¥ for {img_path}: {e}")
            return f"[Failed: {str(e)}]"

    def _handle_json_response_with_correction(
        self,
        raw_text: str,
        original_prompt: str,
        is_title_translation: bool = False,
        is_glossary_extraction: bool = False,
        is_text_translation: bool = False,
        is_vision_translation: bool = False,
        image_part: Optional[Any] = None
    ) -> Any:
        """
        å¤„ç† JSON å“åº”ï¼Œä¼˜åŒ–è§£æé¡ºåºï¼š
        1. å…ˆå°è¯•æ ‡å‡†JSONè§£æ
        2. å°è¯•å»é™¤ä»£ç å—åè§£æ
        3. å°è¯•æ­£åˆ™è¡¨è¾¾å¼å…œåº•è§£æ
        4. åªæœ‰ä»¥ä¸Šå…¨éƒ¨å¤±è´¥åï¼Œæ‰è¯·æ±‚æ¨¡å‹è‡ªæˆ‘ä¿®æ­£
        """
        final_parsed_data = None
        current_raw_text = raw_text

        for attempt in range(self.settings.processing.json_repair_retries + 1):
            # ========== é˜¶æ®µ1ï¼šæ ‡å‡†JSONè§£æ ==========
            try:
                final_parsed_data = self._repair_json_content(current_raw_text)
                logger.debug("âœ… æ ‡å‡†JSONè§£ææˆåŠŸ")
                return final_parsed_data
            except JSONParseError as e:
                logger.debug(f"âš ï¸ æ ‡å‡†JSONè§£æå¤±è´¥: {e}")
            
            # ========== é˜¶æ®µ2ï¼šæ­£åˆ™è¡¨è¾¾å¼å…œåº•è§£æ ==========
            try:
                if is_text_translation:
                    fallback_result = self._regex_fallback(current_raw_text)
                    if fallback_result and len(fallback_result) > 0:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯çœŸæ­£çš„ç¿»è¯‘å¤±è´¥æ ‡ç­¾
                        if fallback_result[0].get("translation") != "[Translation Failed - JSON Parse Error]":
                            logger.info(f"âœ… æ­£åˆ™è¡¨è¾¾å¼è§£ææˆåŠŸï¼Œæå– {len(fallback_result)} æ¡ç¿»è¯‘")
                            return fallback_result
                elif is_title_translation or is_glossary_extraction:
                    fallback_result = self._regex_fallback_for_dict_like(current_raw_text)
                    if fallback_result:
                        logger.info(f"âœ… æ­£åˆ™è¡¨è¾¾å¼è§£ææˆåŠŸï¼ˆå­—å…¸æ ¼å¼ï¼‰")
                        return fallback_result
            except Exception as e:
                logger.debug(f"âš ï¸ æ­£åˆ™è¡¨è¾¾å¼è§£æå¤±è´¥: {e}")
            
            # ========== é˜¶æ®µ3ï¼šæ¨¡å‹è‡ªæˆ‘ä¿®æ­£ï¼ˆä»…å½“å‰ä¸¤é˜¶æ®µéƒ½å¤±è´¥æ—¶ï¼‰ ==========
            if attempt < self.settings.processing.json_repair_retries:
                logger.warning(f"âš ï¸ JSON è§£æå¤±è´¥ (å°è¯• {attempt+1}/{self.settings.processing.json_repair_retries + 1}): [MEDIUM] æ ‡å‡†è§£æå’Œæ­£åˆ™è§£æå‡å¤±è´¥")
                logger.info(f"ğŸ’¡ å»ºè®®: å°è¯•è¯·æ±‚æ¨¡å‹è‡ªæˆ‘ä¿®æ­£ (å‰©ä½™ {self.settings.processing.json_repair_retries - attempt} æ¬¡)")
                logger.info("ğŸ”„ å°è¯•è¯·æ±‚æ¨¡å‹è‡ªæˆ‘ä¿®æ­£...")
                
                corrected_data = self._attempt_json_self_correction(
                    original_prompt=original_prompt,
                    failed_json=current_raw_text,
                    error_message="JSONè§£æå’Œæ­£åˆ™è§£æå‡å¤±è´¥",
                    retries_left=self.settings.processing.json_repair_retries - attempt,
                    is_vision=is_vision_translation,
                    image_part=image_part
                )
                
                if corrected_data:
                    logger.info("âœ… æ¨¡å‹è‡ªæˆ‘ä¿®æ­£æˆåŠŸ")
                    final_parsed_data = corrected_data
                    return final_parsed_data
                else:
                    logger.warning("âŒ æ¨¡å‹è‡ªæˆ‘ä¿®æ­£å¤±è´¥")
                    # é‡ç½®ä¸ºåŸå§‹æ–‡æœ¬ï¼Œç»§ç»­ä¸‹ä¸€è½®å°è¯•
                    current_raw_text = raw_text
            else:
                logger.warning("âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ‰€æœ‰è§£ææ–¹æ³•å‡å¤±è´¥ã€‚")
                break

        # ========== æœ€ç»ˆå…œåº•ï¼šè¿”å›é”™è¯¯æ ‡è®° ==========
        logger.error(f"âŒ æ‰€æœ‰è§£ææ–¹æ³•å¤±è´¥ï¼ˆæ ‡å‡†JSON + æ­£åˆ™ + æ¨¡å‹ä¿®æ­£ï¼‰")
        
        if is_text_translation:
            logger.warning("âš ï¸ è¿”å›ç¿»è¯‘å¤±è´¥æ ‡ç­¾ä»¥ä¿è¯è¾“å‡ºæ–‡ä»¶å®Œæ•´æ€§")
            return [{"id": 1, "translation": "[Translation Failed - All Parsing Methods Exhausted]"}]
        elif is_title_translation or is_glossary_extraction:
            return {}
        elif is_vision_translation:
            return {}
        
        return final_parsed_data

    def _parse_json_response(self, text: str) -> List[Dict[str, Any]]:
        """è§£ææ–‡æœ¬ç¿»è¯‘çš„ JSON å“åº”ï¼Œæ”¯æŒå¤šç§æ ¼å¼"""
        try:
            # è°ƒç”¨æ–°çš„å¤„ç†å‡½æ•°ï¼Œå¹¶æ˜ç¡®è¿™æ˜¯æ–‡æœ¬ç¿»è¯‘åœºæ™¯
            # æ³¨æ„: è¿™é‡Œ original_prompt ä¼ é€’ç©ºå­—ç¬¦ä¸²ï¼Œå› ä¸º _parse_json_response ä¹‹å‰æ²¡æœ‰ç›´æ¥çš„ prompt ä¿¡æ¯ã€‚
            # åªæœ‰å½“åŸå§‹ API è°ƒç”¨å¤±è´¥æ—¶ï¼Œ_handle_json_response_with_correction æ‰ä¼šä½¿ç”¨åˆ° original_prompt è¿›è¡Œè‡ªæˆ‘ä¿®æ­£ã€‚
            # å¦‚æœæ˜¯ _parse_json_response ç‹¬ç«‹è°ƒç”¨ï¼ˆä¾‹å¦‚ä»ç¼“å­˜è¯»å–ï¼‰ï¼Œé‚£ä¹ˆ original_prompt ç¡®å®æ˜¯æœªçŸ¥çš„ã€‚
            result = self._handle_json_response_with_correction(text, "", is_text_translation=True)
            if isinstance(result, list):
                return result
            elif isinstance(result, dict) and 'translations' in result:
                return result['translations']
            else:
                return []
        except Exception as e:
            logger.error(f"âŒ æœ€ç»ˆJSONè§£æå¤±è´¥ï¼ŒåŒ…æ‹¬ä¿®æ­£å’Œæ­£åˆ™å›é€€: {e}")
            return []

    def _repair_json_content(self, text: str) -> Any:
        """ä¿®å¤ JSON å­—ç¬¦ä¸² (åªè¿›è¡Œä»£ç å—å»é™¤ï¼Œä¸è¿›è¡Œé«˜çº§å­—ç¬¦ä¸²ä¿®å¤)"""
        # å»é™¤ Markdown ä»£ç å—
        pattern = r'^```(?:json)?\s*(.*)\s*```$'
        match = re.search(pattern, text, re.DOTALL)
        if match:
            text = match.group(1)

        try:
            return json.loads(text)
        except json.JSONDecodeError as e:
            # ä¸å†è¿›è¡Œå†…éƒ¨é«˜çº§ä¿®å¤ï¼Œç›´æ¥æŠ›å‡ºï¼Œç”±ä¸Šå±‚å¤„ç†è‡ªæˆ‘ä¿®æ­£
            raise JSONParseError(f"Initial JSON parse failed: {e}")

    def _regex_fallback(self, text: str) -> List[Dict[str, Any]]:
        """æ­£åˆ™è¡¨è¾¾å¼å…œåº•è§£æ"""
        logger.info("ğŸ”„ Using regex fallback for JSON parsing...")

        # ç­–ç•¥1: æ ‡å‡†JSONæ ¼å¼
        pattern = r'"id":\s*(\d+),\s*"translation":\s*"(.*?)(?<!\\)"(?=\s*\}|\s*,)'
        matches = re.findall(pattern, text, re.DOTALL)

        if not matches:
            # ç­–ç•¥2: å•å¼•å·æ ¼å¼
            pattern_sq = r"'id':\s*(\d+),\s*'translation':\s*'(.*?)'(?=\s*\}|\s*,)"
            matches = re.findall(pattern_sq, text, re.DOTALL)

        if not matches:
            # ç­–ç•¥3: æ›´å®½æ¾çš„åŒ¹é…ï¼ˆå¤„ç†ä¸å®Œæ•´çš„JSONï¼‰
            pattern_loose = r'"id":\s*(\d+).*?"translation":\s*"(.*?)"'
            matches = re.findall(pattern_loose, text, re.DOTALL)

        if not matches:
            # ç­–ç•¥4: æåº¦å®½æ¾çš„åŒ¹é…
            pattern_ultra = r'id["\s:]+(\d+).*?translation["\s:]+["\']([^"\']*?)["\']'
            matches = re.findall(pattern_ultra, text, re.DOTALL | re.IGNORECASE)

        if not matches:
            logger.error(f"âŒ Regex fallback failed completely. Original text: {repr(text[:500])}")
            # è¿”å›ç¿»è¯‘å¤±è´¥çš„æ ‡ç­¾ï¼Œç¡®ä¿è‡³å°‘èƒ½ç”Ÿæˆå®Œæ•´çš„è¾“å‡ºæ–‡ä»¶
            logger.warning("âš ï¸ Returning translation failure tag to ensure output file integrity.")
            return [{"id": 1, "translation": "[Translation Failed - JSON Parse Error]"}]

        logger.debug(f"âœ… Regex found {len(matches)} matches.")
        return [{"id": int(mid), "translation": mtext.replace('\\"', '"').replace("\\'", "'")} for mid, mtext in matches]


# ========================================================================
# å¼‚æ­¥ç¿»è¯‘å®¢æˆ·ç«¯
# ========================================================================

class AsyncGeminiTranslator(BaseAsyncTranslator):
    """å¼‚æ­¥ Gemini ç¿»è¯‘å®¢æˆ·ç«¯ï¼Œæ”¯æŒå¹¶å‘æ‰¹é‡ç¿»è¯‘ã€‚
    
    ç»§æ‰¿è‡ª BaseAsyncTranslatorï¼Œå®ç° Gemini çš„å¼‚æ­¥ç¿»è¯‘é€»è¾‘ã€‚
    æ”¯æŒä¸Šä¸‹æ–‡ç®¡ç†å™¨è‡ªåŠ¨èµ„æºæ¸…ç†ã€‚
    """

    def __init__(self, base_translator: GeminiTranslator):
        """
        Args:
            base_translator: åŸºç¡€çš„ GeminiTranslator å®ä¾‹ï¼Œç”¨äºå¤ç”¨é…ç½®å’ŒåŒæ­¥æ–¹æ³•
        """
        # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        super().__init__(base_translator)
        
        self.generation_config = base_translator.generation_config
        self.cache_refs = base_translator.cache_refs
        self.prompt_manager = base_translator.prompt_manager  # å¤ç”¨ prompt_manager
        
        # ä» settings è·å–çº¿ç¨‹æ± å¤§å°ï¼Œé»˜è®¤ 10
        max_workers = getattr(base_translator.settings.processing, 'async_max_workers', 10)
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        
        # ä» settings è·å–è§†è§‰ API ä¿¡å·é‡ï¼Œé»˜è®¤ 3
        self.vision_semaphore_limit = getattr(base_translator.settings.processing, 'vision_max_concurrent', 3)
        
        # ä» settings è·å–è¶…æ—¶é…ç½®ï¼Œé»˜è®¤ 300 ç§’
        self.async_timeout = getattr(base_translator.settings.processing, 'async_batch_timeout', 300)
        
        logger.debug(f"ğŸ”§ AsyncGeminiTranslator initialized: workers={max_workers}, vision_sem={self.vision_semaphore_limit}, timeout={self.async_timeout}s")
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡ºï¼Œè‡ªåŠ¨æ¸…ç†èµ„æº"""
        self.cleanup()
        return False
    
    def __enter__(self):
        """åŒæ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£ï¼ˆå…¼å®¹æ€§ï¼‰"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """åŒæ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡º"""
        self.cleanup()
        return False
    
    def __del__(self):
        """ææ„å‡½æ•°ï¼Œç¡®ä¿èµ„æºæ¸…ç†"""
        try:
            self.cleanup()
        except Exception:
            pass
        
    async def translate_text_batch_async(
        self,
        segments: SegmentList,
        context: str,
        glossary: Optional[Dict[str, str]] = None
    ) -> List[str]:
        """
        å¼‚æ­¥æ‰¹é‡ç¿»è¯‘æ–‡æœ¬segment
        
        å°†segmentsåˆ†æˆæ›´å°çš„chunkå¹¶å‘ç¿»è¯‘ï¼Œå¤§å¹…æå‡é€Ÿåº¦
        ç‰¹æ€§ï¼šè¶…æ—¶æ§åˆ¶ã€è‡ªåŠ¨é‡è¯•ã€å¼‚å¸¸éš”ç¦»
        """
        if not segments:
            return []
        
        logger.info(f"ğŸš€ ä½¿ç”¨å¼‚æ­¥æ¨¡å¼ç¿»è¯‘ {len(segments)} ä¸ªæ–‡æœ¬æ®µï¼ˆè¶…æ—¶: {self.async_timeout}sï¼‰...")
        
        # å°† segments åˆ†æˆå°æ‰¹æ¬¡ (é¿å…å•ä¸ªè¯·æ±‚è¿‡å¤§)
        chunk_size = min(5, self.settings.processing.batch_size)
        chunks = [segments[i:i + chunk_size] for i in range(0, len(segments), chunk_size)]
        
        # å¹¶å‘ç¿»è¯‘æ‰€æœ‰ chunkï¼Œå¸¦è¶…æ—¶æ§åˆ¶
        tasks = [
            self._translate_single_chunk_async(chunk, context, glossary, retry_count=2)
            for chunk in chunks
        ]
        
        try:
            # æ·»åŠ æ€»ä½“è¶…æ—¶æ§åˆ¶
            chunk_results = await asyncio.wait_for(
                asyncio.gather(*tasks, return_exceptions=True),
                timeout=self.async_timeout
            )
        except asyncio.TimeoutError:
            logger.error(f"âŒ å¼‚æ­¥ç¿»è¯‘è¶…æ—¶ï¼ˆ{self.async_timeout}sï¼‰ï¼Œå–æ¶ˆæ‰€æœ‰ä»»åŠ¡")
            # è¶…æ—¶æ—¶è¿”å›å¤±è´¥æ ‡è®°
            return [f"[Failed: Timeout after {self.async_timeout}s]"] * len(segments)
        
        # åˆå¹¶ç»“æœ
        results = []
        for chunk, chunk_result in zip(chunks, chunk_results):
            if isinstance(chunk_result, Exception):
                logger.error(f"âŒ Chunk ç¿»è¯‘å¤±è´¥: {chunk_result}")
                # ä¸ºå¤±è´¥çš„chunkå¡«å……å¤±è´¥æ ‡è®°ï¼Œä½¿ç”¨å®é™…çš„chunkå¤§å°
                actual_chunk_size = len(chunk)
                results.extend([f"[Failed: {str(chunk_result)}]"] * actual_chunk_size)
            else:
                results.extend(chunk_result)
        
        success_count = len([r for r in results if not r.startswith('[Failed')])
        logger.info(f"âœ… å¼‚æ­¥ç¿»è¯‘å®Œæˆï¼ŒæˆåŠŸ {success_count} / {len(segments)}")
        return results[:len(segments)]  # ç¡®ä¿è¿”å›æ­£ç¡®æ•°é‡çš„ç»“æœ

    async def _translate_single_chunk_async(
        self,
        segments: SegmentList,
        context: str,
        glossary: Optional[Dict[str, str]] = None,
        retry_count: int = 0
    ) -> List[str]:
        """å¼‚æ­¥ç¿»è¯‘å•ä¸ª chunkï¼Œæ”¯æŒé‡è¯•"""
        
        # å‡†å¤‡è¾“å…¥æ•°æ®
        input_data = [
            {
                "id": seg.segment_id,
                "original": seg.original_text,
                "context": (context or "No Context")[-self.settings.processing.max_context_length:]
            }
            for seg in segments
        ]
        input_json = json.dumps(input_data, ensure_ascii=False)
        
        # æ ¼å¼åŒ–æœ¯è¯­è¡¨
        glossary_text = "N/A"
        if glossary:
            glossary_text = "\n".join([f"- **{k}**: Must be translated as **{v}**" for k, v in glossary.items()])
        
        # æˆªå–ä¸Šä¸‹æ–‡
        safe_context = context[-self.settings.processing.max_context_length:] if context else "No Context"
        
        # æ ¼å¼åŒ– Prompt - ä½¿ç”¨ prompt_manager
        original_prompt = self.prompt_manager.format_text_prompt(
            context=safe_context,
            input_json=input_json,
            glossary=glossary_text
        )
        
        # è·å–å½“å‰äº‹ä»¶å¾ªç¯ï¼ˆå®‰å…¨æ–¹å¼ï¼‰
        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            # å¦‚æœæ²¡æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œå›é€€åˆ° get_event_loop
            loop = asyncio.get_event_loop()
        
        def _call_with_cache():
            return self.base._generate_content(
                contents=original_prompt,
                generation_config=self.generation_config,
                use_cache=True,
                purpose="Async Text Translation"
            )
        
        # é‡è¯•é€»è¾‘
        last_error = None
        for attempt in range(retry_count + 1):
            try:
                # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥çš„ API è°ƒç”¨ï¼ˆä½¿ç”¨ç¼“å­˜å¦‚æœå¯ç”¨ï¼‰
                response = await loop.run_in_executor(self.executor, _call_with_cache)
                
                # raw_text = response.text.strip()
                raw_text = response.candidates[0].content.parts[0].text
                # è§£æå“åº”ï¼ˆå¤ç”¨åŒæ­¥æ–¹æ³•ï¼‰
                output_list = self.base._handle_json_response_with_correction(
                    raw_text,
                    original_prompt,
                    is_text_translation=True
                )
                
                # æ˜ å°„ç»“æœ
                input_ids = [s.segment_id for s in segments]
                output_map = {
                    int(item['id']): str(item.get('translation', ''))
                    for item in output_list
                    if 'id' in item and str(item['id']).isdigit()
                }
                
                # ç”Ÿæˆæœ€ç»ˆç»“æœ
                results = [output_map.get(uid, "[Translation Failed]") for uid in input_ids]
                
                if attempt > 0:
                    logger.info(f"âœ… Chunk ç¿»è¯‘é‡è¯•æˆåŠŸï¼ˆç¬¬ {attempt + 1} æ¬¡å°è¯•ï¼‰")
                
                return results
            
            except Exception as e:
                last_error = e
                if attempt < retry_count:
                    wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                    logger.warning(f"âš ï¸ Chunk ç¿»è¯‘å¤±è´¥ï¼ˆå°è¯• {attempt + 1}/{retry_count + 1}ï¼‰ï¼Œ{wait_time}s åé‡è¯•: {e}")
                    await asyncio.sleep(wait_time)
                else:
                    logger.error(f"âŒ Chunk ç¿»è¯‘å¤±è´¥ï¼Œå·²ç”¨å°½æ‰€æœ‰é‡è¯•: {e}")
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›å¤±è´¥æ ‡è®°
        input_ids = [s.segment_id for s in segments]
        return [f"[Failed: {str(last_error)}]"] * len(input_ids)

    async def translate_vision_batch_async(
        self,
        segments: SegmentList,
        context: str,
        glossary: Optional[Dict[str, str]] = None
    ) -> List[str]:
        """
        å¼‚æ­¥æ‰¹é‡ç¿»è¯‘åŒ…å«å›¾åƒçš„segment
        
        ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°ï¼Œé¿å…è§¦å‘ Gemini é€Ÿç‡é™åˆ¶
        """
        if not segments:
            return []
        
        logger.info(f"ğŸ–¼ï¸ ä½¿ç”¨å¼‚æ­¥æ¨¡å¼ç¿»è¯‘ {len(segments)} ä¸ªè§†è§‰æ®µï¼ˆå¹¶å‘é™åˆ¶: {self.vision_semaphore_limit}ï¼‰...")
        
        # åˆ›å»ºä¿¡å·é‡ï¼Œé™åˆ¶å¹¶å‘è§†è§‰ API è°ƒç”¨æ•°ï¼ˆä»é…ç½®è¯»å–ï¼‰
        semaphore = asyncio.Semaphore(self.vision_semaphore_limit)
        
        # åˆ›å»ºç¿»è¯‘ä»»åŠ¡
        tasks = []
        for seg in segments:
            if seg.content_type == "image" and seg.image_path:
                task = self._call_vision_api_async(
                    seg.image_path,
                    context,
                    semaphore
                )
            else:
                # æ–‡æœ¬é™çº§å¤„ç†
                task = self._translate_text_fallback_async(seg, context, glossary)
            
            tasks.append(task)
        
        # ç­‰å¾…æ‰€æœ‰ç¿»è¯‘å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸ç»“æœ
        final_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"âŒ è§†è§‰ç¿»è¯‘å¤±è´¥ (segment {segments[i].segment_id}): {result}")
                final_results.append(f"[Failed: {str(result)}]")
            else:
                final_results.append(result)
        
        logger.info(f"âœ… å¼‚æ­¥è§†è§‰ç¿»è¯‘å®Œæˆ")
        return final_results

    async def _call_vision_api_async(
        self,
        img_path: str,
        context: str,
        semaphore: asyncio.Semaphore,
        retry_count: int = 2
    ) -> str:
        """å¼‚æ­¥è°ƒç”¨è§†è§‰ APIï¼Œä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘ï¼Œæ”¯æŒé‡è¯•"""
        
        async with semaphore:  # é™åˆ¶å¹¶å‘æ•°
            # è·å–å½“å‰äº‹ä»¶å¾ªç¯ï¼ˆå®‰å…¨æ–¹å¼ï¼‰
            try:
                loop = asyncio.get_running_loop()
            except RuntimeError:
                loop = asyncio.get_event_loop()
            
            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œ I/O ç»‘å®šçš„å›¾åƒå¤„ç†
            def _process_vision():
                # ç›´æ¥è°ƒç”¨åŸºç¡€ç¿»è¯‘å™¨çš„è§†è§‰APIæ–¹æ³•
                return self.base._call_vision_api(img_path, context)
            
            # é‡è¯•é€»è¾‘
            last_error = None
            for attempt in range(retry_count + 1):
                try:
                    result = await loop.run_in_executor(self.executor, _process_vision)
                    
                    # æ·»åŠ å»¶è¿Ÿé¿å…é€Ÿç‡é™åˆ¶
                    await asyncio.sleep(self.settings.processing.vision_rate_limit_delay)
                    
                    if attempt > 0:
                        logger.info(f"âœ… è§†è§‰ API é‡è¯•æˆåŠŸï¼ˆç¬¬ {attempt + 1} æ¬¡å°è¯•ï¼‰: {img_path}")
                    
                    return result
                
                except Exception as e:
                    last_error = e
                    if attempt < retry_count:
                        wait_time = 2 ** attempt
                        logger.warning(f"âš ï¸ è§†è§‰ API å¤±è´¥ï¼ˆå°è¯• {attempt + 1}/{retry_count + 1}ï¼‰ï¼Œ{wait_time}s åé‡è¯•: {img_path}")
                        await asyncio.sleep(wait_time)
                    else:
                        logger.error(f"âŒ è§†è§‰ API å¤±è´¥ï¼Œå·²ç”¨å°½æ‰€æœ‰é‡è¯•: {img_path}")
            
            return f"[Failed: {str(last_error)}]"

    async def _translate_text_fallback_async(
        self,
        segment: ContentSegment,
        context: str,
        glossary: Optional[Dict[str, str]]
    ) -> str:
        """å¼‚æ­¥æ–‡æœ¬é™çº§å¤„ç†"""
        # è·å–å½“å‰äº‹ä»¶å¾ªç¯ï¼ˆå®‰å…¨æ–¹å¼ï¼‰
        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            loop = asyncio.get_event_loop()
        
        def _sync_fallback():
            results = self.base._translate_text_batch(
                [segment],
                context,
                glossary
            )
            return results[0] if results else "[Fallback Failed]"
        
        return await loop.run_in_executor(self.executor, _sync_fallback)

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.executor.shutdown(wait=True)
        logger.info("ğŸ§¹ å¼‚æ­¥ç¿»è¯‘å™¨å·²æ¸…ç†èµ„æº")


# ========================================================================
# OpenAI-compatible (DeepSeek) translator
# ========================================================================


class OpenAICompatibleTranslator(BaseTranslator):
    """OpenAI-compatible ç¿»è¯‘å®¢æˆ·ç«¯ï¼ˆDeepSeek API å…¼å®¹ OpenAI æ ¼å¼ï¼‰ã€‚

    DeepSeek docs:
      - base_url: https://api.deepseek.com (or https://api.deepseek.com/v1)
      - endpoint: POST /chat/completions

    Env vars are provided via Settings.api:
      - API_OPENAI_API_KEY / OPENAI_API_KEY / DEEPSEEK_API_KEY
      - OPENAI_BASE_URL / DEEPSEEK_BASE_URL
      - OPENAI_MODEL / DEEPSEEK_MODEL
    """

    def __init__(self, settings: Settings):
        super().__init__(settings)
        self.prompt_manager = PromptManager(settings)
        self._async_translator: Optional[AsyncOpenAICompatibleTranslator] = None

        self.api_key: Optional[str] = settings.api.openai_api_key
        self.base_url: str = settings.api.openai_base_url
        self.model: str = settings.api.openai_model
        
        # éªŒè¯å’Œä¿®å¤ base_url é…ç½®
        self.base_url = self._validate_and_fix_base_url(self.base_url)
        
        # è‡ªåŠ¨æ£€æµ‹æ˜¯å¦ä¸ºæœ¬åœ°æœåŠ¡ï¼ˆOllamaï¼‰æˆ– DeepSeek API
        # é€‚é… M2 Pro 16GB ç¡¬ä»¶ç¯å¢ƒï¼Œæœ¬åœ°æ¨¡å¼éœ€è¦ç‰¹æ®Šå¤„ç†
        self.is_local: bool = self._detect_local_service(self.base_url)
        self.is_deepseek: bool = self._detect_deepseek_api(self.base_url)
        
        # DeepSeek é•¿æ–‡æœ¬æ¨¡å¼ï¼šè‡ªåŠ¨åˆ‡æ¢ä¸ºå• message æ¨¡å¼ï¼ˆsystem + instruction + mode + context + promptï¼‰
        # åŸå› ï¼šDeepSeek å¯¹é•¿ä¸Šä¸‹æ–‡æ”¯æŒæ›´å¥½ï¼Œä¸” system message å¯èƒ½å½±å“æ€§èƒ½
        self.use_long_text_mode: bool = self.is_deepseek
        
        if self.is_local:
            logger.info("ğŸ  æ£€æµ‹åˆ°æœ¬åœ°æ¨¡å¼ï¼ˆOllamaï¼‰")
            logger.info(f"   - æœåŠ¡åœ°å€: {self.base_url}")
            logger.info(f"   - æ¨¡å‹: {self.model}")
            logger.info("   - å·²å¯ç”¨ M2 Pro ä¼˜åŒ–ï¼šnum_ctx=8192, num_thread=10")
        elif self.is_deepseek:
            logger.info("ğŸš€ æ£€æµ‹åˆ° DeepSeek API")
            logger.info(f"   - API åœ°å€: {self.base_url}")
            logger.info(f"   - æ¨¡å‹: {self.model}")
            logger.info("   - å·²å¯ç”¨é•¿æ–‡æœ¬æ¨¡å¼ï¼ˆæ‰€æœ‰å†…å®¹åˆå¹¶ä¸ºå•ä¸ª user messageï¼‰")
        else:
            logger.info("â˜ï¸  æ£€æµ‹åˆ°äº‘ç«¯æ¨¡å¼ï¼ˆOpenAIï¼‰")
            logger.info(f"   - API åœ°å€: {self.base_url}")
            logger.info(f"   - æ¨¡å‹: {self.model}")

        if not self.api_key:
            raise APIAuthenticationError(
                "OpenAI-compatible API key is missing. Set API_OPENAI_API_KEY (or OPENAI_API_KEY/DEEPSEEK_API_KEY).",
                context={"setting": "API_OPENAI_API_KEY"},
            )
    
    def _validate_and_fix_base_url(self, base_url: str) -> str:
        """éªŒè¯å¹¶ä¿®å¤ base_url é…ç½®
        
        Args:
            base_url: åŸå§‹çš„ base_url é…ç½®
            
        Returns:
            ä¿®å¤åçš„ base_url
        """
        if not base_url:
            raise ValueError("OPENAI_BASE_URL ä¸èƒ½ä¸ºç©º")
            
        base = base_url.strip()
        
        # å¦‚æœå·²ç»æ˜¯å®Œæ•´çš„ URLï¼Œç›´æ¥è¿”å›
        if base.startswith(('http://', 'https://')):
            return base
            
        # å¤„ç†å¸¸è§çš„é”™è¯¯é…ç½®
        if 'deepseek' in base.lower():
            # DeepSeek å¸¸è§é”™è¯¯é…ç½®
            logger.warning(f"âš ï¸ æ£€æµ‹åˆ°ä¸å®Œæ•´çš„ DeepSeek URL é…ç½®: '{base}'")
            logger.warning("   è‡ªåŠ¨ä¿®å¤ä¸º: https://api.deepseek.com")
            return 'https://api.deepseek.com'
        elif 'localhost' in base or '127.0.0.1' in base:
            # æœ¬åœ°æœåŠ¡
            if not base.startswith('http://'):
                fixed_url = f'http://{base}'
                logger.warning(f"âš ï¸ æœ¬åœ°æœåŠ¡ URL ç¼ºå°‘åè®®: '{base}' -> '{fixed_url}'")
                return fixed_url
            return base
        else:
            # å…¶ä»–äº‘ç«¯æœåŠ¡ï¼Œå‡è®¾æ˜¯åŸŸåï¼Œæ·»åŠ  https://
            fixed_url = f'https://{base}'
            logger.warning(f"âš ï¸ æ£€æµ‹åˆ°ä¸å®Œæ•´çš„ URL é…ç½®: '{base}' -> '{fixed_url}'")
            logger.warning("   å¦‚æœè¿™æ˜¯é”™è¯¯çš„ï¼Œè¯·åœ¨é…ç½®ä¸­æä¾›å®Œæ•´çš„ URLï¼ˆåŒ…å« http:// æˆ– https://ï¼‰")
            return fixed_url

    def _detect_local_service(self, base_url: str) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºæœ¬åœ°æœåŠ¡ï¼ˆOllamaï¼‰
        
        Args:
            base_url: API åŸºç¡€ URL
            
        Returns:
            True å¦‚æœæ˜¯æœ¬åœ°æœåŠ¡ï¼ˆåŒ…å« localhost æˆ– 127.0.0.1ï¼‰
        """
        if not base_url:
            return False
        url_lower = base_url.lower()
        return 'localhost' in url_lower or '127.0.0.1' in url_lower
    
    def _detect_deepseek_api(self, base_url: str) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸º DeepSeek API
        
        Args:
            base_url: API åŸºç¡€ URL
            
        Returns:
            True å¦‚æœæ˜¯ DeepSeek APIï¼ˆåŒ…å« api.deepseek.comï¼‰
        """
        if not base_url:
            return False
        url_lower = base_url.lower()
        return 'deepseek.com' in url_lower or 'deepseek' in url_lower

    @property
    def async_translator(self) -> Optional['AsyncOpenAICompatibleTranslator']:
        # æœ¬åœ°æ¨¡å¼å¼ºåˆ¶åŒæ­¥ç¿»è¯‘ï¼Œé™ä½åŠŸè€—å’Œå†…å­˜å‹åŠ›
        if self.is_local:
            logger.debug("ğŸ”’ æœ¬åœ°æ¨¡å¼ç¦ç”¨å¼‚æ­¥ç¿»è¯‘ï¼ˆé™ä½åŠŸè€—ï¼‰")
            return None
        
        if self._async_translator is None:
            self._async_translator = AsyncOpenAICompatibleTranslator(self)
        return self._async_translator

    def translate_batch(
        self,
        segments: SegmentList,
        context: str = "",
        glossary: Optional[Dict[str, str]] = None,
    ) -> List[str]:
        if not segments:
            return []

        has_image = any(seg.content_type == "image" for seg in segments)
        if has_image:
            return self._translate_vision_batch(segments, context)
        return self._translate_text_batch(segments, context, glossary)

    def translate_titles(self, titles: List[str]) -> TranslationMap:
        if not titles:
            return {}

        input_json_str = json.dumps(titles, ensure_ascii=False)
        original_prompt = self.prompt_manager.format_title_prompt(input_json_str)

        raw_text = self._chat_completions(
            system_instruction=self.prompt_manager.get_system_instruction(use_vision=False),
            user_content=original_prompt,
        )

        parsed_data = self._handle_json_response_with_repair(
            raw_text=raw_text,
            original_prompt=original_prompt,
            is_dict_like=True,
        )

        if isinstance(parsed_data, dict):
            return {str(k): str(v) for k, v in parsed_data.items() if isinstance(v, str)}

        if isinstance(parsed_data, list) and parsed_data:
            result: Dict[str, str] = {}
            for item in parsed_data:
                if isinstance(item, dict):
                    for k, v in item.items():
                        if k != 'id':
                            result[str(k)] = str(v)
            return result

        return {}

    def extract_glossary(self, segments: SegmentList) -> Dict[str, str]:
        if not segments:
            return {}

        text_to_analyze: List[str] = []
        for seg in segments:
            if seg.is_translated:
                text_to_analyze.append(
                    f"Original: {seg.original_text}\nTranslated: {seg.translated_text}\n---"
                )

        if not text_to_analyze:
            return {}

        content_sample = "\n".join(text_to_analyze)
        original_prompt = f"""
You are an expert linguist and terminologist.
Analyze the following pairs of original and translated text. Identify all key, recurring, or specialized terms (like names, places, philosophical concepts, technical jargon) and create a definitive glossary.

RULES:
1. The output MUST be a flat JSON object.
2. Keys are the original English terms.
3. Values are their corresponding Chinese translations found in the text.
4. Focus on nouns and proper nouns.
5. Be precise. The goal is to enforce consistency.

Text to Analyze:
<text>
{content_sample[:8000]}
</text>

Return ONLY the JSON object.
""".strip()

        raw_text = self._chat_completions(
            system_instruction="You output JSON only.",
            user_content=original_prompt,
        )

        parsed = self._handle_json_response_with_repair(
            raw_text=raw_text,
            original_prompt=original_prompt,
            is_dict_like=True,
        )

        final_glossary: Dict[str, str] = {}
        if isinstance(parsed, dict):
            for k, v in parsed.items():
                if k and v:
                    final_glossary[str(k).strip()] = str(v).strip()
        return final_glossary

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=1, max=20),
        retry=retry_if_exception_type((APIError,)),
        reraise=True,
    )
    def _translate_text_batch(
        self,
        segments: SegmentList,
        context: str,
        glossary: Optional[Dict[str, str]] = None,
    ) -> List[str]:
        input_data = [{"id": seg.segment_id, "text": seg.original_text} for seg in segments]
        input_json = json.dumps(input_data, ensure_ascii=False)

        safe_context = context[-self.settings.processing.max_context_length:] if context else "No Context"

        glossary_text = "N/A"
        if glossary:
            glossary_text = "\n".join(
                [f"- **{k}**: Must be translated as **{v}**" for k, v in glossary.items()]
            )

        # DeepSeek é•¿æ–‡æœ¬æ¨¡å¼ï¼šå°† system instruction åµŒå…¥åˆ° user content ä¸­
        if self.use_long_text_mode:
            system_instruction = self.prompt_manager.get_system_instruction(use_vision=False)
            user_prompt = self.prompt_manager.format_text_prompt(
                context=safe_context,
                input_json=input_json,
                glossary=glossary_text,
            )
            # å°† system instruction å’Œ user prompt åˆå¹¶ä¸ºå®Œæ•´çš„é•¿æ–‡æœ¬ prompt
            combined_prompt = f"{system_instruction}\n\n{'='*80}\n\n{user_prompt}"
            
            raw_text = self._chat_completions(
                system_instruction="",  # é•¿æ–‡æœ¬æ¨¡å¼ä¸‹ system_instruction ä¸ºç©º
                user_content=combined_prompt,
            )
        else:
            # æ ‡å‡†æ¨¡å¼ï¼šsystem å’Œ user åˆ†ç¦»
            original_prompt = self.prompt_manager.format_text_prompt(
                context=safe_context,
                input_json=input_json,
                glossary=glossary_text,
            )

            raw_text = self._chat_completions(
                system_instruction=self.prompt_manager.get_system_instruction(use_vision=False),
                user_content=original_prompt,
            )

        output_list = self._handle_json_response_with_repair(
            raw_text=raw_text,
            original_prompt=combined_prompt if self.use_long_text_mode else original_prompt,
            is_text_translation=True,
        )

        input_ids = [s.segment_id for s in segments]
        output_map = {
            int(item['id']): str(item.get('translation', ''))
            for item in output_list
            if isinstance(item, dict) and 'id' in item and str(item['id']).isdigit()
        }
        return [output_map.get(uid, "[Failed: Missing translation]") for uid in input_ids]

    def _translate_vision_batch(self, segments: SegmentList, context: str) -> List[str]:
        results: List[str] = []
        current_context = context[-self.settings.processing.max_context_length:] if context else ""

        for seg in segments:
            if seg.content_type == "image" and seg.image_path:
                results.append(self._call_vision_api(seg.image_path, current_context))
            else:
                fallback = self._translate_text_batch([seg], current_context, glossary=None)
                results.append(fallback[0] if fallback else "[Fallback Failed]")

            current_context += f"\n{results[-1]}"
            if len(current_context) > self.settings.processing.max_context_length:
                current_context = current_context[-self.settings.processing.max_context_length:]

        return results

    def _call_vision_api(self, img_path: str, context: str) -> str:
        original_prompt = self.prompt_manager.format_vision_prompt(context)

        try:
            with open(img_path, 'rb') as f:
                b64 = base64.b64encode(f.read()).decode('ascii')
            image_url = f"data:image/png;base64,{b64}"

            raw_text = self._chat_completions(
                system_instruction=self.prompt_manager.get_system_instruction(use_vision=True),
                user_content=[
                    {"type": "text", "text": original_prompt},
                    {"type": "image_url", "image_url": {"url": image_url}},
                ],
            )

            parsed = self._handle_json_response_with_repair(
                raw_text=raw_text,
                original_prompt=original_prompt,
                is_dict_like=True,
            )
            if isinstance(parsed, dict) and 'translation' in parsed:
                return str(parsed['translation'])
            return "[Failed: Invalid JSON Response]"
        except Exception as e:
            logger.error(f"âŒ OpenAI-compatible Vision API è°ƒç”¨å¤±è´¥ for {img_path}: {e}")
            return f"[Failed: {str(e)}]"

    def _build_chat_completions_url(self) -> str:
        """æ„å»º Chat Completions API URL
        
        é’ˆå¯¹æœ¬åœ° Ollama æœåŠ¡çš„è·¯å¾„ä¿®å¤é€»è¾‘ï¼š
        - æœ¬åœ°æ¨¡å¼ï¼šå¼ºåˆ¶ä½¿ç”¨ http://127.0.0.1:11434/v1/chat/completions
        - äº‘ç«¯æ¨¡å¼ï¼ˆDeepSeekï¼‰ï¼šä¿æŒåŸé€»è¾‘
        """
        base = (self.base_url or '').rstrip('/')
        
        # æœ¬åœ°æ¨¡å¼ï¼šå¼ºåˆ¶ä½¿ç”¨ 127.0.0.1:11434/v1/chat/completionsï¼ˆOllama æ ‡å‡†æ¥å£ï¼‰
        if self.is_local:
            # ç»Ÿä¸€ä½¿ç”¨ 127.0.0.1 è€Œé localhostï¼Œé¿å… DNS è§£æé—®é¢˜
            return 'http://127.0.0.1:11434/v1/chat/completions'
        
        # äº‘ç«¯æ¨¡å¼ï¼šç¡®ä¿ base_url æ˜¯å®Œæ•´çš„ URL
        if not base.startswith(('http://', 'https://')):
            # å¦‚æœä¸æ˜¯å®Œæ•´çš„ URLï¼Œå°è¯•ä¿®å¤å¸¸è§çš„é”™è¯¯é…ç½®
            if 'deepseek' in base.lower():
                # DeepSeek å¸¸è§é”™è¯¯é…ç½®ä¿®å¤
                logger.warning(f"âš ï¸ æ£€æµ‹åˆ°ä¸å®Œæ•´çš„ DeepSeek URL é…ç½®: '{base}'ï¼Œè‡ªåŠ¨ä¿®å¤ä¸ºæ ‡å‡† URL")
                return 'https://api.deepseek.com/v1/chat/completions'
            else:
                # å…¶ä»–æœåŠ¡ï¼Œå°è¯•æ·»åŠ  https:// å‰ç¼€
                logger.warning(f"âš ï¸ æ£€æµ‹åˆ°ä¸å®Œæ•´çš„ URL é…ç½®: '{base}'ï¼Œå°è¯•æ·»åŠ  https:// å‰ç¼€")
                base = f'https://{base}'
        
        # äº‘ç«¯æ¨¡å¼ï¼šDeepSeek æ”¯æŒä¸¤ç§æ ¼å¼
        # https://api.deepseek.com/chat/completions æˆ–
        # https://api.deepseek.com/v1/chat/completions
        if base.endswith('/v1'):
            return base + '/chat/completions'
        return base + '/chat/completions'

    def _chat_completions(self, system_instruction: str, user_content: Any) -> str:
        """è°ƒç”¨ Chat Completions API
        
        æœ¬åœ°æ¨¡å¼ä¼˜åŒ–ï¼ˆM2 Pro 16GBï¼‰ï¼š
        - å¼ºåˆ¶ 120s è¶…æ—¶ï¼ˆæœ¬åœ°æ¨ç†è¾ƒæ…¢ï¼‰
        - æ³¨å…¥ options å­—æ®µï¼šnum_ctx=8192ï¼ˆé•¿æ–‡æœ¬è®°å¿†ï¼‰ï¼Œnum_thread=10ï¼ˆé€‚é… M2 Pro æ ¸å¿ƒæ•°ï¼‰
        
        DeepSeek é•¿æ–‡æœ¬æ¨¡å¼ï¼š
        - æ‰€æœ‰å†…å®¹å·²é¢„å…ˆåˆå¹¶åˆ° user_content ä¸­ï¼Œsystem_instruction ä¸ºç©º
        - æ ¼å¼ï¼šå®Œæ•´çš„é•¿æ–‡æœ¬ prompt åŒ…å« system instruction + mode + context + input
        - åŸå› ï¼šDeepSeek å¯¹é•¿ä¸Šä¸‹æ–‡æ”¯æŒæ›´å¥½ï¼Œä¸”é¿å… system message é™åˆ¶
        """
        # DeepSeek é•¿æ–‡æœ¬æ¨¡å¼ï¼šæ‰€æœ‰å†…å®¹å·²é¢„å…ˆåˆå¹¶ï¼Œæ— éœ€é¢å¤–å¤„ç†
        if self.use_long_text_mode:
            payload = {
                "model": self.model,
                "messages": [
                    {"role": "user", "content": user_content},
                ],
                "temperature": 0.2,
                "stream": False,
            }
            logger.debug("ğŸ“ ä½¿ç”¨é•¿æ–‡æœ¬æ¨¡å¼ï¼ˆæ‰€æœ‰å†…å®¹é¢„å…ˆåˆå¹¶ï¼‰")
        else:
            # æ ‡å‡†æ¨¡å¼ï¼šsystem + user åˆ†ç¦»
            payload = {
                "model": self.model,
                "messages": [
                    {"role": "system", "content": system_instruction},
                    {"role": "user", "content": user_content},
                ],
                "temperature": 0.2,
                "stream": False,
            }
        
        # è®°å½•å‘é€ç»™APIçš„æ–‡æœ¬é•¿åº¦
        total_text_length = 0
        for message in payload["messages"]:
            content = message["content"]
            if isinstance(content, str):
                total_text_length += len(content)
            elif isinstance(content, list):
                # å¤„ç†å¤šæ¨¡æ€å†…å®¹
                for item in content:
                    if isinstance(item, dict) and "text" in item:
                        total_text_length += len(item["text"])
        
        logger.info(f"ğŸ“¤ å‘é€APIè¯·æ±‚ - æ–‡æœ¬æ€»é•¿åº¦: {total_text_length} å­—ç¬¦")
        if self.use_long_text_mode:
            logger.debug("   ğŸ“Š é•¿æ–‡æœ¬æ¨¡å¼: System Instruction + åˆ†éš”ç¬¦ + Mode + Glossary + Context + Input JSON")
        else:
            logger.debug("   ğŸ“Š æ ‡å‡†æ¨¡å¼: System Instruction + User Content")
        
        # æœ¬åœ°æ¨¡å¼ï¼šæ³¨å…¥ Ollama ä¸“ç”¨å‚æ•°ï¼Œé’ˆå¯¹ M2 Pro 16GB ä¼˜åŒ–
        if self.is_local:
            payload["options"] = {
                "num_ctx": 1024,      # è¿›ä¸€æ­¥é™ä½ï¼šä» 2048 åˆ° 1024ï¼ˆé€‚åº”è¶…é•¿ä¸Šä¸‹æ–‡ï¼‰
                "num_thread": 1,      # è¿›ä¸€æ­¥é™ä½ï¼šä» 2 åˆ° 1ï¼ˆå•çº¿ç¨‹ï¼Œæä½å†…å­˜å‹åŠ›ï¼‰
            }
            logger.debug("ğŸ”§ æœ¬åœ°æ¨¡å¼ payload å·²æ³¨å…¥ options: num_ctx=1024, num_thread=1")

        url = self._build_chat_completions_url()
        data = json.dumps(payload).encode('utf-8')
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {self.api_key}',
        }
        
        # åŠ¨æ€è¶…æ—¶ï¼šæœ¬åœ°æ¨¡å¼å¼ºåˆ¶ 120sï¼Œäº‘ç«¯æ¨¡å¼æ ¹æ®æœåŠ¡è°ƒæ•´
        if self.is_deepseek:
            timeout = 120  # DeepSeekå“åº”è¾ƒæ…¢ï¼Œå¢åŠ åˆ°120ç§’
            logger.debug(f"â±ï¸  DeepSeekæ¨¡å¼è¶…æ—¶è®¾ç½®: {timeout}s")
        elif self.is_local:
            timeout = 120 if self.is_local else self.settings.processing.request_timeout
            if self.is_local:
                logger.debug(f"â±ï¸  æœ¬åœ°æ¨¡å¼è¶…æ—¶è®¾ç½®: {timeout}s")
        else:
            timeout = self.settings.processing.request_timeout

        req = request.Request(url, data=data, headers=headers, method='POST')
        try:
            with request.urlopen(req, timeout=timeout) as resp:
                resp_text = resp.read().decode('utf-8')
        except error.HTTPError as e:
            body = e.read().decode('utf-8', errors='replace') if hasattr(e, 'read') else ''
            raise APIError(f"OpenAI-compatible HTTPError: {e.code} {e.reason} {body[:200]}")
        except error.URLError as e:
            raise APITimeoutError(f"OpenAI-compatible request failed: {e}")
        except TimeoutError as e:
            raise APITimeoutError(f"OpenAI-compatible request timeout: {e}")

        try:
            parsed = json.loads(resp_text)
            content = parsed['choices'][0]['message']['content']
            if not isinstance(content, str):
                return json.dumps(content, ensure_ascii=False)
            return content.strip()
        except Exception as e:
            raise APIError(f"OpenAI-compatible response parse failed: {e}")

    def _strip_code_fences(self, text: str) -> str:
        pattern = r'^```(?:json)?\s*(.*)\s*```$'
        match = re.search(pattern, text, re.DOTALL)
        return match.group(1) if match else text

    def _handle_json_response_with_repair(
        self,
        raw_text: str,
        original_prompt: str,
        *,
        is_text_translation: bool = False,
        is_dict_like: bool = False,
    ) -> Any:
        current = raw_text

        for _ in range(self.settings.processing.json_repair_retries + 1):
            try:
                current = self._strip_code_fences(current)
                return json.loads(current)
            except json.JSONDecodeError as e:
                last_err = str(e)

            if is_text_translation:
                try:
                    fallback = self._regex_fallback_for_list(current)
                    if fallback:
                        return fallback
                except Exception:
                    pass

            repair_prompt = self.prompt_manager.format_json_repair_prompt(
                original_prompt=original_prompt,
                broken_json=current,
                error_details=last_err,
            )
            current = self._chat_completions(
                system_instruction=self.prompt_manager.get_system_instruction(use_vision=False),
                user_content=repair_prompt,
            )

        if is_text_translation:
            return [{"id": 1, "translation": "[Translation Failed - All Parsing Methods Exhausted]"}]
        if is_dict_like:
            return {}
        raise JSONParseError("Failed to parse JSON after repair attempts")

    def _regex_fallback_for_list(self, text: str) -> List[Dict[str, Any]]:
        pattern = r'"id":\s*(\d+),\s*"translation":\s*"(.*?)(?<!\\)"(?=\s*\}|\s*,)'
        matches = re.findall(pattern, text, re.DOTALL)
        return [
            {"id": int(mid), "translation": mtext.replace('\\"', '"').replace("\\'", "'")}
            for mid, mtext in matches
        ]


class AsyncOpenAICompatibleTranslator(BaseAsyncTranslator):
    """å¼‚æ­¥ OpenAI-compatible ç¿»è¯‘å™¨ï¼ˆçº¿ç¨‹æ± åŒ…è£…ï¼ŒåŒæ­¥HTTPè¯·æ±‚å¹¶å‘æ‰§è¡Œï¼‰ã€‚
    
    å¹¶å‘æ§åˆ¶ç­–ç•¥ï¼ˆM2 Pro 16GB ä¼˜åŒ–ï¼‰ï¼š
    - æœ¬åœ°æ¨¡å¼ï¼ˆOllamaï¼‰ï¼šmax_workers=2ï¼Œé˜²æ­¢ 16GB ç»Ÿä¸€å†…å­˜æº¢å‡º
    - äº‘ç«¯æ¨¡å¼ï¼ˆDeepSeekï¼‰ï¼šmax_workers=10ï¼Œå……åˆ†åˆ©ç”¨ç½‘ç»œå¹¶å‘
    æ”¯æŒä¸Šä¸‹æ–‡ç®¡ç†å™¨è‡ªåŠ¨èµ„æºæ¸…ç†ã€‚
    """

    def __init__(self, base_translator: OpenAICompatibleTranslator):
        super().__init__(base_translator)
        
        # åŠ¨æ€å¹¶å‘æ§åˆ¶ï¼šæ ¹æ®æœåŠ¡ç±»å‹è°ƒæ•´å¹¶å‘æ•°
        if base_translator.is_local:
            # æœ¬åœ°æ¨¡å¼ï¼š2 å¹¶å‘ï¼ˆM2 Pro 16GB é™åˆ¶ï¼Œé¿å…æ˜¾å­˜æº¢å‡ºï¼‰
            max_workers = 2
        elif base_translator.is_deepseek:
            # DeepSeekï¼š3 å¹¶å‘ï¼ˆé¿å…è§¦å‘é€Ÿç‡é™åˆ¶ï¼ŒDeepSeekå“åº”è¾ƒæ…¢ï¼‰
            max_workers = 3
        else:
            # å…¶ä»–äº‘ç«¯æ¨¡å¼ï¼š10 å¹¶å‘ï¼ˆç½‘ç»œ I/O å¯†é›†ï¼Œå¯ä»¥é«˜å¹¶å‘ï¼‰
            max_workers = 10
            
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self._max_workers = max_workers  # ä¿å­˜ç”¨äºæ—¥å¿—
        
        # æ—¥å¿—è¾“å‡ºå½“å‰å¹¶å‘æ¨¡å¼
        if base_translator.is_local:
            logger.info("ğŸ”’ å¼‚æ­¥ç¿»è¯‘å™¨å·²åˆå§‹åŒ–ï¼ˆæœ¬åœ°æ¨¡å¼ï¼‰")
            logger.info("   - å¹¶å‘æ•°: 2ï¼ˆM2 Pro 16GB å†…å­˜ä¿æŠ¤ï¼‰")
            logger.info("   - åŸå› : é˜²æ­¢æœ¬åœ°æ¨¡å‹å¹¶å‘å¯¼è‡´ç»Ÿä¸€å†…å­˜æº¢å‡º")
        elif base_translator.is_deepseek:
            logger.info("ğŸš€ å¼‚æ­¥ç¿»è¯‘å™¨å·²åˆå§‹åŒ–ï¼ˆDeepSeekæ¨¡å¼ï¼‰")
            logger.info("   - å¹¶å‘æ•°: 3ï¼ˆé€Ÿç‡é™åˆ¶ä¿æŠ¤ï¼‰")
            logger.info("   - åŸå› : DeepSeekå“åº”è¾ƒæ…¢ï¼Œé¿å…è§¦å‘APIé™æµ")
        else:
            logger.info("ğŸš€ å¼‚æ­¥ç¿»è¯‘å™¨å·²åˆå§‹åŒ–ï¼ˆäº‘ç«¯æ¨¡å¼ï¼‰")
            logger.info("   - å¹¶å‘æ•°: 10ï¼ˆç½‘ç»œ I/O ä¼˜åŒ–ï¼‰")
            logger.info("   - é€‚ç”¨äº: OpenAI ç­‰äº‘ç«¯æœåŠ¡")
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡ºï¼Œè‡ªåŠ¨æ¸…ç†èµ„æº"""
        self.cleanup()
        return False
    
    def __enter__(self):
        """åŒæ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£ï¼ˆå…¼å®¹æ€§ï¼‰"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """åŒæ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡º"""
        self.cleanup()
        return False
    
    def __del__(self):
        """ææ„å‡½æ•°ï¼Œç¡®ä¿èµ„æºæ¸…ç†"""
        try:
            self.cleanup()
        except Exception:
            pass

    async def translate_text_batch_async(
        self,
        segments: SegmentList,
        context: str,
        glossary: Optional[Dict[str, str]] = None,
    ) -> List[str]:
        if not segments:
            return []

        # è·å–å½“å‰äº‹ä»¶å¾ªç¯ï¼ˆå®‰å…¨æ–¹å¼ï¼‰
        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            loop = asyncio.get_event_loop()

        def _sync():
            return self.base._translate_text_batch(segments, context, glossary)

        return await loop.run_in_executor(self.executor, _sync)

    async def translate_vision_batch_async(
        self,
        segments: SegmentList,
        context: str,
        glossary: Optional[Dict[str, str]] = None,
    ) -> List[str]:
        if not segments:
            return []

        # è·å–å½“å‰äº‹ä»¶å¾ªç¯ï¼ˆå®‰å…¨æ–¹å¼ï¼‰
        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            loop = asyncio.get_event_loop()

        def _sync_one(seg: ContentSegment) -> str:
            if seg.content_type == 'image' and seg.image_path:
                return self.base._call_vision_api(seg.image_path, context)
            fallback = self.base._translate_text_batch([seg], context, glossary)
            return fallback[0] if fallback else "[Fallback Failed]"

        tasks = [loop.run_in_executor(self.executor, _sync_one, seg) for seg in segments]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        final: List[str] = []
        for r in results:
            if isinstance(r, Exception):
                final.append(f"[Failed: {str(r)}]")
            else:
                final.append(r)
        return final

    def cleanup(self):
        self.executor.shutdown(wait=True)
        logger.info("ğŸ§¹ OpenAI-compatible å¼‚æ­¥ç¿»è¯‘å™¨å·²æ¸…ç†èµ„æº")
